{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q53LGvBNfCj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import base64\n",
        "import re\n",
        "import sqlite3\n",
        "import time\n",
        "from datetime import datetime\n",
        "from flask import Flask, request, jsonify, g\n",
        "from tensorflow.keras.models import load_model # load_model para cargar todo de una vez\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from PIL import Image\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos la aplicación Flask\n",
        "app = Flask(__name__)\n",
        "# --- AJUSTE PARA AWS ---\n",
        "application = app\n",
        "\n",
        "# --- CONFIGURACIÓN ---\n",
        "MODEL_VERSION = \"1.0.0\"\n",
        "TARGET_SIZE = (265, 265)\n",
        "LABELS = [\"Clase_0\", \"Clase_1\"]\n",
        "DB_FILE = \"hospital_data.db\" # Archivo de base de datos local\n",
        "\n",
        "# --- CARGA DEL MODELO (.keras) ---\n",
        "# Ahora solo necesitamos un archivo único\n",
        "MODEL_FILE = 'classifier-resnet-model9.keras'\n",
        "model = None\n",
        "\n",
        "try:\n",
        "    if os.path.exists(MODEL_FILE):\n",
        "        print(f\"Cargando modelo desde {MODEL_FILE}...\")\n",
        "        # load_model se encarga de todo (arquitectura + pesos)\n",
        "        model = load_model(MODEL_FILE)\n",
        "        print(\"¡Modelo .keras cargado exitosamente!\")\n",
        "    else:\n",
        "        print(f\"ADVERTENCIA: No se encontró {MODEL_FILE}. La predicción fallará.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error cargando modelo: {e}\")\n",
        "\n",
        "# --- GESTIÓN DE BASE DE DATOS (SQLite) ---\n",
        "\n",
        "def get_db():\n",
        "    \"\"\"Conexión a base de datos por petición.\"\"\"\n",
        "    db = getattr(g, '_database', None)\n",
        "    if db is None:\n",
        "        db = g._database = sqlite3.connect(DB_FILE)\n",
        "        db.row_factory = sqlite3.Row\n",
        "    return db\n",
        "\n",
        "@app.teardown_appcontext\n",
        "def close_connection(exception):\n",
        "    \"\"\"Cierra la conexión al terminar la petición.\"\"\"\n",
        "    db = getattr(g, '_database', None)\n",
        "    if db is not None:\n",
        "        db.close()\n",
        "\n",
        "def init_db():\n",
        "    \"\"\"Crea la tabla si no existe (se ejecuta al inicio).\"\"\"\n",
        "    with app.app_context():\n",
        "        db = get_db()\n",
        "        db.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS predictions (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                date TEXT,\n",
        "                filename TEXT,\n",
        "                predicted_class TEXT,\n",
        "                confidence REAL,\n",
        "                corrected_label TEXT\n",
        "            )\n",
        "        ''')\n",
        "        db.commit()\n",
        "\n",
        "# Inicializamos la DB al arrancar el script\n",
        "init_db()\n",
        "\n",
        "# --- FUNCIONES AUXILIARES DE IMAGEN ---\n",
        "def decode_base64_image(base64_string):\n",
        "    image_data = re.sub('^data:image/.+;base64,', '', base64_string)\n",
        "    image_bytes = base64.b64decode(image_data)\n",
        "    return Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "def prepare_image(image, target):\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    image = image.resize(target)\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "# ==========================================\n",
        "# DEFINICIÓN DE ENDPOINTS\n",
        "# ==========================================\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return jsonify({\n",
        "        \"status\": \"online\",\n",
        "        \"model_type\": \".keras (Modern Format)\",\n",
        "        \"endpoints\": {\n",
        "            \"predict\": \"POST /predict (Body: image)\",\n",
        "            \"history\": \"GET /history (Query: limit, class)\",\n",
        "            \"train\": \"POST /admin/train (Body: epochs, lr)\",\n",
        "            \"feedback\": \"PUT /feedback/<id> (Path + Body)\"\n",
        "        }\n",
        "    })\n",
        "\n",
        "# --- 1. RUTA CON PARÁMETROS EN EL BODY (Standard POST) ---\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = {\"success\": False}\n",
        "    image_bytes = None\n",
        "    filename = \"upload_base64\"\n",
        "\n",
        "    # Lógica de recepción de imagen (Archivo o Base64)\n",
        "    if request.files.get(\"image\"):\n",
        "        image_file = request.files[\"image\"]\n",
        "        filename = image_file.filename\n",
        "        image_bytes = Image.open(io.BytesIO(image_file.read()))\n",
        "    elif request.json and \"image\" in request.json:\n",
        "        image_bytes = decode_base64_image(request.json[\"image\"])\n",
        "\n",
        "    if image_bytes and model:\n",
        "        # 1. Predecir\n",
        "        processed_image = prepare_image(image_bytes, target=TARGET_SIZE)\n",
        "        preds = model.predict(processed_image)\n",
        "        pred_idx = np.argmax(preds, axis=1)[0]\n",
        "        prob = float(np.max(preds))\n",
        "        pred_label = LABELS[pred_idx]\n",
        "\n",
        "        # 2. Guardar en Base de Datos\n",
        "        db = get_db()\n",
        "        cursor = db.cursor()\n",
        "        cursor.execute(\n",
        "            'INSERT INTO predictions (date, filename, predicted_class, confidence) VALUES (?, ?, ?, ?)',\n",
        "            (datetime.now().isoformat(), filename, pred_label, prob)\n",
        "        )\n",
        "        db.commit()\n",
        "        prediction_id = cursor.lastrowid\n",
        "\n",
        "        # 3. Responder\n",
        "        data.update({\n",
        "            \"prediction_id\": prediction_id,\n",
        "            \"prediction\": pred_label,\n",
        "            \"confidence\": f\"{prob:.2%}\",\n",
        "            \"success\": True\n",
        "        })\n",
        "        return jsonify(data)\n",
        "\n",
        "    return jsonify({\"error\": \"Falta imagen o modelo no cargado\"}), 400\n",
        "\n",
        "# --- 2. RUTA CON PARÁMETROS EN LA QUERY (Query Params) ---\n",
        "@app.route(\"/history\", methods=[\"GET\"])\n",
        "def get_history():\n",
        "    db = get_db()\n",
        "    limit = request.args.get('limit', 10)\n",
        "    class_filter = request.args.get('class_filter')\n",
        "\n",
        "    query = \"SELECT * FROM predictions\"\n",
        "    params = []\n",
        "\n",
        "    if class_filter:\n",
        "        query += \" WHERE predicted_class = ?\"\n",
        "        params.append(class_filter)\n",
        "\n",
        "    query += \" ORDER BY id DESC LIMIT ?\"\n",
        "    params.append(limit)\n",
        "\n",
        "    cursor = db.execute(query, params)\n",
        "    rows = cursor.fetchall()\n",
        "\n",
        "    history = [dict(row) for row in rows]\n",
        "\n",
        "    return jsonify({\"count\": len(history), \"data\": history})\n",
        "\n",
        "# --- 3. RUTA CON PARÁMETROS EN EL PATH + BODY (Combinado) ---\n",
        "@app.route(\"/feedback/<int:prediction_id>\", methods=[\"PUT\"])\n",
        "def update_feedback(prediction_id):\n",
        "    if not request.json or 'correct_label' not in request.json:\n",
        "        return jsonify({\"error\": \"Falta 'correct_label' en el JSON body\"}), 400\n",
        "\n",
        "    new_label = request.json['correct_label']\n",
        "\n",
        "    if new_label not in LABELS:\n",
        "        return jsonify({\"error\": f\"Clase inválida. Use: {LABELS}\"}), 400\n",
        "\n",
        "    db = get_db()\n",
        "    cursor = db.execute(\"SELECT id FROM predictions WHERE id = ?\", (prediction_id,))\n",
        "    if not cursor.fetchone():\n",
        "        return jsonify({\"error\": \"ID de predicción no encontrado\"}), 404\n",
        "\n",
        "    db.execute(\n",
        "        \"UPDATE predictions SET corrected_label = ? WHERE id = ?\",\n",
        "        (new_label, prediction_id)\n",
        "    )\n",
        "    db.commit()\n",
        "\n",
        "    return jsonify({\"message\": f\"Feedback guardado para predicción {prediction_id}\", \"status\": \"updated\"})\n",
        "\n",
        "# --- 4. RUTA DE NEGOCIO AVANZADA (Simulacro de Entrenamiento) --- NO RECOMENDADO XQ PUEDE TIRAR AWS free\n",
        "@app.route(\"/admin/train\", methods=[\"POST\"])\n",
        "def train_model():\n",
        "    params = request.json or {}\n",
        "    epochs = params.get(\"epochs\", 5)\n",
        "    learning_rate = params.get(\"learning_rate\", 0.001)\n",
        "\n",
        "    print(f\"Iniciando entrenamiento: Epochs={epochs}, LR={learning_rate}\")\n",
        "    time.sleep(2)\n",
        "\n",
        "    global MODEL_VERSION\n",
        "    MODEL_VERSION = f\"2.0.{int(time.time())}\"\n",
        "\n",
        "    return jsonify({\n",
        "        \"message\": \"Entrenamiento finalizado (Simulado)\",\n",
        "        \"new_version\": MODEL_VERSION,\n",
        "        \"config_used\": {\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"architecture\": \"ResNet50 (.keras)\"\n",
        "        }\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "v0DHS9NNPWfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa64dbf5-2889-409d-c707-e1d590c58cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando modelo desde classifier-resnet-model9.keras...\n",
            "¡Modelo .keras cargado exitosamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INICIO DEL SERVIDOR ---\n",
        "if __name__ == \"__main__\":\n",
        "    # IMPORTANTE: En la nube, no usamos puerto fijo 5000.\n",
        "    # AWS nos asigna un puerto a través de una variable de entorno.\n",
        "    port = int(os.environ.get('PORT', 5000))\n",
        "\n",
        "    # debug=False para producción (¡muy importante por seguridad!)\n",
        "    app.run(host='0.0.0.0', port=port, debug=False)"
      ],
      "metadata": {
        "id": "u-pplfixPZhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddebbb3a-4dde-4e40-9973-054fb1edfc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tHealth check — GET /health y GET /health/model Fundamental para deployments y monitoreo. La segunda verifica que el modelo esté cargado correctamente.\n",
        "2.\t2. Predicción — POST /predict Recibe la imagen (como archivo o base64), ejecuta inferencia, devuelve probabilidad y clasificación.\n",
        "3.\t4. Metadata del modelo — GET /model/info Devuelve versión del modelo, clases que detecta, tamaño de input esperado. Muy útil para debugging y para el frontend.\n"
      ],
      "metadata": {
        "id": "XuFYDlpucsML"
      }
    }
  ]
}