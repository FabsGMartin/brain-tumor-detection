{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading NVIDIA libraries from /home/fabit/brain-tumor-detection/.venv/lib/python3.12/site-packages/nvidia...\n",
      "NVIDIA libraries preloaded.\n"
     ]
    }
   ],
   "source": [
    "# FIX FOR RTX 5080 / CUDA 12 HARDWARE\n",
    "# This cell patches the environment to ensure TensorFlow finds the GPU correctly\n",
    "import os\n",
    "import sys\n",
    "import ctypes\n",
    "\n",
    "def preload_nvidia_libs():\n",
    "    try:\n",
    "        # Attempt to locate site-packages content\n",
    "        paths_to_check = []\n",
    "        if hasattr(sys, 'prefix'):\n",
    "            paths_to_check.append(os.path.join(sys.prefix, \"lib\", f\"python{sys.version_info.major}.{sys.version_info.minor}\", \"site-packages\", \"nvidia\"))\n",
    "        \n",
    "        nvidia_base = None\n",
    "        for p in paths_to_check:\n",
    "            if os.path.exists(p):\n",
    "                nvidia_base = p\n",
    "                break\n",
    "        \n",
    "        if not nvidia_base:\n",
    "            print(\"Could not find nvidia packages to preload. GPU might not be detected.\")\n",
    "            return\n",
    "\n",
    "        libs_to_load = [\n",
    "            (\"cudnn/lib\", \"libcudnn.so.9\"),\n",
    "            (\"cublas/lib\", \"libcublas.so.12\"),\n",
    "            (\"cublas/lib\", \"libcublasLt.so.12\"),\n",
    "            (\"cufft/lib\", \"libcufft.so.11\"),\n",
    "            (\"curand/lib\", \"libcurand.so.10\"),\n",
    "            (\"cusolver/lib\", \"libcusolver.so.11\"),\n",
    "            (\"cusparse/lib\", \"libcusparse.so.12\"),\n",
    "            (\"nccl/lib\", \"libnccl.so.2\"),\n",
    "        ]\n",
    "        \n",
    "        print(f\"Preloading NVIDIA libraries from {nvidia_base}...\")\n",
    "        for subdir, libname in libs_to_load:\n",
    "            path = os.path.join(nvidia_base, subdir, libname)\n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    ctypes.CDLL(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to load {libname}: {e}\")\n",
    "        print(\"NVIDIA libraries preloaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preload: {e}\")\n",
    "\n",
    "preload_nvidia_libs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TwGy3okqKwa"
   },
   "source": [
    "- Data source: https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0oz3ShXF0Qa"
   },
   "source": [
    "# IMPORT LIBRARIES AND DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BDv169iyF3aL"
   },
   "outputs": [],
   "source": [
    "# Configuration and paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set base directory (notebooks are in notebooks/, data and models are in parent directory)\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "\n",
    "# Ensure directories exist\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configuration constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_SIZE = (256, 256)\n",
    "EPOCHS = 50\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import cv2\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score,RocCurveDisplay, precision_score, f1_score\n",
    "import random\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765235193.855486     639 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1765235193.899048     639 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765235194.620005     639 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Custom Callback that forces printing to stdout to ensure visibility\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class ForceProgressPrint(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f'\\nğŸš€ Starting Epoch {epoch + 1}...')\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch % 10 == 0:  # Print every 10 batches\n",
    "            loss = logs.get('loss', 0)\n",
    "            acc = logs.get('accuracy', 0)\n",
    "            print(f'   Batch {batch}: Loss = {loss:.4f}, Accuracy = {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oDTMhZP6QNx",
    "outputId": "1578de72-fcce-4347-bc86-ecf083359fbc"
   },
   "outputs": [],
   "source": [
    "# Google Colab code removed - running locally\n",
    "# Data should be in the 'data' directory relative to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6gXD9ntF7Ob",
    "outputId": "de6adaca-5047-4728-9325-503d76ad9c3f"
   },
   "outputs": [],
   "source": [
    "# Google Colab directory change removed - running locally\n",
    "# Working directory is already set to the project root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Gh9HnkX7GCot",
    "outputId": "340e87d9-535f-41a0-a21f-74e53f946969"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "1  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "2  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "3  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "4  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "5  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "6  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "7  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "8  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "9  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
       "\n",
       "                                           mask_path  mask  \n",
       "0  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
       "1  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
       "2  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
       "3  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
       "4  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
       "5  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
       "6  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
       "7  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
       "8  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
       "9  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from data directory\n",
    "brain_df = pd.read_csv(DATA_DIR / 'route_label.csv', index_col=0)\n",
    "brain_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3alYoe9Goif"
   },
   "source": [
    "# RESNET50 CLASSIFIER MODEL \n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YivtLcVAGuPV",
    "outputId": "5b715e66-d973-429a-a9ba-7e944ca29726"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3899, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the patient id column\n",
    "brain_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1snunGTqGxBV"
   },
   "outputs": [],
   "source": [
    "# Convert the data in mask column to string format, to use categorical mode in flow_from_dataframe\n",
    "\n",
    "brain_df['mask'] = brain_df['mask'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-zRg-XBZI-n",
    "outputId": "1cf04491-6ddd-4219-8180-8720da319f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3899 entries, 0 to 3898\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_path  3899 non-null   object\n",
      " 1   mask_path   3899 non-null   object\n",
      " 2   mask        3899 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 121.8+ KB\n"
     ]
    }
   ],
   "source": [
    "brain_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4qsN7ScgGx5b"
   },
   "outputs": [],
   "source": [
    "# split the data into train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(brain_df, test_size = 0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uDAsPPAQQjM2"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "P00gJa-QGy2f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a data generator which scales the data from 0 to 1 and makes validation split of 0.15\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    validation_split = 0.15,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIv9crZ0GzOG",
    "outputId": "55181f6b-51af-4a18-f79f-b789f1373fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2817 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 497 validated image filenames belonging to 2 classes.\n",
      "Found 585 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory=str(BASE_DIR),\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "subset=\"training\",\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory=str(BASE_DIR),\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "subset=\"validation\",\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=IMAGE_SIZE)\n",
    "\n",
    "# Create a data generator for test images\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test,\n",
    "directory=str(BASE_DIR),\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=False,\n",
    "class_mode='categorical',\n",
    "target_size=IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Lx-Go4Icqd",
    "outputId": "83d61b26-4f1f-45b2-ca6e-c30185a58324"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765232678.972359    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.972758    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.973045    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.973059    4691 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "W0000 00:00:1765232678.975284    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.975582    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.975869    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232678.975882    4691 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "W0000 00:00:1765232679.108327    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232679.108608    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765232679.108877    4691 cuda_executor.cc:1840] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "I0000 00:00:1765232679.108903    4691 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13153 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5080, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    }
   ],
   "source": [
    "# Get the ResNet50 base model\n",
    "basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8XZAiVyyIerF",
    "outputId": "93b01a22-824a-40f3-f47a-baaa00e96de8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnet50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"resnet50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_pad           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> â”‚ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_bn            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_relu          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pad           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pool          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block4_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block4_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block4_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block4_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block4_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block4_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block5_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block5_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block5_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block5_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block6_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block6_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block6_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block6_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_pad           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262\u001b[0m, \u001b[38;5;34m262\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚      \u001b[38;5;34m9,472\u001b[0m â”‚ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_bn            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_relu          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pad           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pool          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m4,160\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m131,584\u001b[0m â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block4_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block4_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block4_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block4_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block4_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block4_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block5_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block5_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block5_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block5_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block6_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block6_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block6_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block6_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚    \u001b[38;5;34m524,800\u001b[0m â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m2,099,200\u001b[0m â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,534,592</span> (89.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,534,592\u001b[0m (89.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "phnUpI52Ifwk"
   },
   "outputs": [],
   "source": [
    "# freeze the model weights\n",
    "\n",
    "for layer in basemodel.layers:\n",
    "  layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nxXUAWdvIpoh"
   },
   "outputs": [],
   "source": [
    "# Add classification head to the base model\n",
    "\n",
    "headmodel = basemodel.output\n",
    "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
    "headmodel = Flatten(name= 'flatten')(headmodel)\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.3)(headmodel)#\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.3)(headmodel)\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.3)(headmodel)\n",
    "headmodel = Dense(2, activation = 'softmax')(headmodel)\n",
    "\n",
    "model = Model(inputs = basemodel.input, outputs = headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vz9uVaUTGtIP",
    "outputId": "8a1f1b69-1f6f-4621-ecb7-b3bdd201b598"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_pad           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> â”‚ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_bn            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_relu          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pad           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pool          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block4_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block4_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block4_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚ conv3_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block4_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block4_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block4_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block5_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block5_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block5_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block5_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block6_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block6_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block6_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚ conv4_block6_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block1_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block1_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_0_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_0_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block2_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block2_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block2_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_1_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_1_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block3_1_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_2_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_relu â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_2_bâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_conv â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block3_2_râ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_bn   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block3_3_câ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_add    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv5_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_out    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_addâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_outâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ average_pooling2â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_pad           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262\u001b[0m, \u001b[38;5;34m262\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚      \u001b[38;5;34m9,472\u001b[0m â”‚ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_bn            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1_relu          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pad           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1_pool          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m4,160\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m131,584\u001b[0m â”‚ conv2_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block4_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block4_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block4_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚ conv3_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv3_block4_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m512\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ conv3_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block4_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block4_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block4_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block4_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block4_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block5_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block5_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block5_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block5_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block5_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block6_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block6_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block6_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚ conv4_block6_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv4_block6_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m1024\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚    \u001b[38;5;34m524,800\u001b[0m â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block1_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m2,099,200\u001b[0m â”‚ conv4_block6_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block1_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_0_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_0_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_0_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block1_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block1_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block2_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block2_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block2_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block2_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block2_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_1_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_1_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_1_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚  \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block3_1_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_2_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_2_relu â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_2_bâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_conv â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block3_2_râ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_3_bn   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block3_3_câ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_add    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv5_block3_3_bâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv5_block3_out    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_addâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_outâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ average_pooling2â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m2,097,408\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚        \u001b[38;5;34m514\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,817,218</span> (98.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,817,218\u001b[0m (98.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,764,098</span> (98.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,764,098\u001b[0m (98.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "k2pTe3e-IraV"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ILjx0SpQItJY"
   },
   "outputs": [],
   "source": [
    "# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "# save the best model with least validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model2.keras\"), verbose=1,save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urOsztzRhWBS",
    "outputId": "1642d355-81b4-4d74-fd5c-2242cf2292be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765232693.856803    4897 service.cc:153] XLA service 0x79d8740c6430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765232693.856841    4897 service.cc:161]   StreamExecutor device (0): NVIDIA GeForce RTX 5080, Compute Capability 12.0a\n",
      "I0000 00:00:1765232694.221470    4897 dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1765232696.495727    4897 cuda_dnn.cc:461] Loaded cuDNN version 91700\n",
      "I0000 00:00:1765232697.606376    5050 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_MatMul_22', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1765232709.734503    5049 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1765232710.779457    5049 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1765232710.886928    5049 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1765232715.530731    4897 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1765232715.611095    4897 device_compiler.h:208] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.8416, Accuracy = 0.5156\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - accuracy: 0.5967 - loss: 1.0367   Batch 10: Loss = 0.8202, Accuracy = 0.6648\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.6442 - loss: 0.8960   Batch 20: Loss = 0.7139, Accuracy = 0.7083\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 688ms/step - accuracy: 0.6678 - loss: 0.8252    Batch 30: Loss = 0.6376, Accuracy = 0.7272\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m2s\u001b[0m 583ms/step - accuracy: 0.6862 - loss: 0.7695   Batch 40: Loss = 0.5667, Accuracy = 0.7563\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - accuracy: 0.6930 - loss: 0.7506\n",
      "Epoch 1: val_loss improved from None to 12.51945, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model2.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 682ms/step - accuracy: 0.7646 - loss: 0.5544 - val_accuracy: 0.3661 - val_loss: 12.5194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 1, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0YGCNd9Iykz",
    "outputId": "82bfcc4f-2d4d-4bd8-edfd-56778da34767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8627 - loss: 0.3056\n",
      "Epoch 1: val_loss improved from None to 0.66587, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 327ms/step - accuracy: 0.8663 - loss: 0.2970 - val_accuracy: 0.6272 - val_loss: 0.6659\n",
      "Epoch 2/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 186ms/step - accuracy: 0.8750 - loss: 0.2938\n",
      "Epoch 2: val_loss improved from 0.66587 to 0.65768, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8750 - loss: 0.2938 - val_accuracy: 0.6384 - val_loss: 0.6577\n",
      "Epoch 3/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8465 - loss: 0.3231\n",
      "Epoch 3: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.8511 - loss: 0.3142 - val_accuracy: 0.6339 - val_loss: 0.6640\n",
      "Epoch 4/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.9062 - loss: 0.3393\n",
      "Epoch 4: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9062 - loss: 0.3393 - val_accuracy: 0.6228 - val_loss: 0.6654\n",
      "Epoch 5/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8987 - loss: 0.2570\n",
      "Epoch 5: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 296ms/step - accuracy: 0.9045 - loss: 0.2569 - val_accuracy: 0.6384 - val_loss: 0.6611\n",
      "Epoch 6/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.9375 - loss: 0.1896\n",
      "Epoch 6: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1896 - val_accuracy: 0.6384 - val_loss: 0.6615\n",
      "Epoch 7/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9172 - loss: 0.2157\n",
      "Epoch 7: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.9099 - loss: 0.2239 - val_accuracy: 0.6406 - val_loss: 0.7082\n",
      "Epoch 8/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9062 - loss: 0.3069\n",
      "Epoch 8: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9062 - loss: 0.3069 - val_accuracy: 0.6540 - val_loss: 0.6850\n",
      "Epoch 9/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9133 - loss: 0.2173\n",
      "Epoch 9: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.9150 - loss: 0.2261 - val_accuracy: 0.6272 - val_loss: 0.6765\n",
      "Epoch 10/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.9375 - loss: 0.2005\n",
      "Epoch 10: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9375 - loss: 0.2005 - val_accuracy: 0.6272 - val_loss: 0.6738\n",
      "Epoch 11/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9239 - loss: 0.2177\n",
      "Epoch 11: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.9237 - loss: 0.2321 - val_accuracy: 0.6161 - val_loss: 0.8766\n",
      "Epoch 12/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.9844 - loss: 0.1148\n",
      "Epoch 12: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.1148 - val_accuracy: 0.6161 - val_loss: 0.7566\n",
      "Epoch 13/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9327 - loss: 0.1992\n",
      "Epoch 13: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9306 - loss: 0.1956 - val_accuracy: 0.5580 - val_loss: 0.7487\n",
      "Epoch 14/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.9062 - loss: 0.2098\n",
      "Epoch 14: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9062 - loss: 0.2098 - val_accuracy: 0.5692 - val_loss: 0.7236\n",
      "Epoch 15/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9455 - loss: 0.1683\n",
      "Epoch 15: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 297ms/step - accuracy: 0.9281 - loss: 0.2144 - val_accuracy: 0.6987 - val_loss: 0.7907\n",
      "Epoch 16/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.8594 - loss: 0.3358\n",
      "Epoch 16: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8594 - loss: 0.3358 - val_accuracy: 0.7054 - val_loss: 0.8569\n",
      "Epoch 17/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9142 - loss: 0.2397\n",
      "Epoch 17: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9197 - loss: 0.2346 - val_accuracy: 0.4375 - val_loss: 3.5729\n",
      "Epoch 18/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9844 - loss: 0.1144\n",
      "Epoch 18: val_loss did not improve from 0.65768\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.1144 - val_accuracy: 0.4554 - val_loss: 3.6397\n",
      "Epoch 19/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9394 - loss: 0.1899\n",
      "Epoch 19: val_loss improved from 0.65768 to 0.55492, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 324ms/step - accuracy: 0.9324 - loss: 0.2002 - val_accuracy: 0.6853 - val_loss: 0.5549\n",
      "Epoch 20/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 188ms/step - accuracy: 0.9062 - loss: 0.2083\n",
      "Epoch 20: val_loss improved from 0.55492 to 0.55373, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9062 - loss: 0.2083 - val_accuracy: 0.7054 - val_loss: 0.5537\n",
      "Epoch 21/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9299 - loss: 0.1918\n",
      "Epoch 21: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 280ms/step - accuracy: 0.9353 - loss: 0.1807 - val_accuracy: 0.6607 - val_loss: 0.8501\n",
      "Epoch 22/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.9688 - loss: 0.1372\n",
      "Epoch 22: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.1372 - val_accuracy: 0.6786 - val_loss: 1.0419\n",
      "Epoch 23/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9175 - loss: 0.2269\n",
      "Epoch 23: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9041 - loss: 0.2481 - val_accuracy: 0.3862 - val_loss: 13.9840\n",
      "Epoch 24/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9375 - loss: 0.1438\n",
      "Epoch 24: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9375 - loss: 0.1438 - val_accuracy: 0.4308 - val_loss: 17.7257\n",
      "Epoch 25/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9254 - loss: 0.1970\n",
      "Epoch 25: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.9321 - loss: 0.1962 - val_accuracy: 0.4442 - val_loss: 9.9631\n",
      "Epoch 26/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 176ms/step - accuracy: 0.9531 - loss: 0.1560\n",
      "Epoch 26: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9531 - loss: 0.1560 - val_accuracy: 0.4621 - val_loss: 7.6510\n",
      "Epoch 27/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9405 - loss: 0.1688\n",
      "Epoch 27: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.9441 - loss: 0.1564 - val_accuracy: 0.7210 - val_loss: 0.9592\n",
      "Epoch 28/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9688 - loss: 0.1538\n",
      "Epoch 28: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9688 - loss: 0.1538 - val_accuracy: 0.7545 - val_loss: 0.8101\n",
      "Epoch 29/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9390 - loss: 0.1760\n",
      "Epoch 29: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 0.9422 - loss: 0.1737 - val_accuracy: 0.7076 - val_loss: 1.8365\n",
      "Epoch 30/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.9062 - loss: 0.2503\n",
      "Epoch 30: val_loss did not improve from 0.55373\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9062 - loss: 0.2503 - val_accuracy: 0.6942 - val_loss: 2.0173\n",
      "Epoch 31/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9559 - loss: 0.1346\n",
      "Epoch 31: val_loss improved from 0.55373 to 0.25983, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 318ms/step - accuracy: 0.9502 - loss: 0.1476 - val_accuracy: 0.9375 - val_loss: 0.2598\n",
      "Epoch 32/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 186ms/step - accuracy: 0.8906 - loss: 0.3195\n",
      "Epoch 32: val_loss improved from 0.25983 to 0.17251, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model3.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8906 - loss: 0.3195 - val_accuracy: 0.9286 - val_loss: 0.1725\n",
      "Epoch 33/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9568 - loss: 0.1317\n",
      "Epoch 33: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.9568 - loss: 0.1266 - val_accuracy: 0.9263 - val_loss: 0.2605\n",
      "Epoch 34/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.9531 - loss: 0.1338\n",
      "Epoch 34: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1338 - val_accuracy: 0.9330 - val_loss: 0.2035\n",
      "Epoch 35/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9363 - loss: 0.1879\n",
      "Epoch 35: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.9201 - loss: 0.2318 - val_accuracy: 0.7188 - val_loss: 3.6561\n",
      "Epoch 36/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.8750 - loss: 0.2161\n",
      "Epoch 36: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8750 - loss: 0.2161 - val_accuracy: 0.7366 - val_loss: 2.7212\n",
      "Epoch 37/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9321 - loss: 0.1952\n",
      "Epoch 37: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 280ms/step - accuracy: 0.9364 - loss: 0.1835 - val_accuracy: 0.9085 - val_loss: 0.3684\n",
      "Epoch 38/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9844 - loss: 0.2245\n",
      "Epoch 38: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.2245 - val_accuracy: 0.9018 - val_loss: 0.3669\n",
      "Epoch 39/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9388 - loss: 0.1865\n",
      "Epoch 39: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.9419 - loss: 0.1912 - val_accuracy: 0.9241 - val_loss: 0.2199\n",
      "Epoch 40/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9375 - loss: 0.2884\n",
      "Epoch 40: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9375 - loss: 0.2884 - val_accuracy: 0.9308 - val_loss: 0.2168\n",
      "Epoch 41/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9473 - loss: 0.1673\n",
      "Epoch 41: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9499 - loss: 0.1652 - val_accuracy: 0.9196 - val_loss: 0.2701\n",
      "Epoch 42/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9531 - loss: 0.1261\n",
      "Epoch 42: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1261 - val_accuracy: 0.9219 - val_loss: 0.2407\n",
      "Epoch 43/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9470 - loss: 0.1487\n",
      "Epoch 43: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.9460 - loss: 0.1601 - val_accuracy: 0.9107 - val_loss: 0.2028\n",
      "Epoch 44/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1726\n",
      "Epoch 44: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1726 - val_accuracy: 0.9085 - val_loss: 0.2412\n",
      "Epoch 45/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9484 - loss: 0.1470\n",
      "Epoch 45: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 298ms/step - accuracy: 0.9215 - loss: 0.2404 - val_accuracy: 0.5446 - val_loss: 3.2157\n",
      "Epoch 46/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.8906 - loss: 0.2240\n",
      "Epoch 46: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8906 - loss: 0.2240 - val_accuracy: 0.5268 - val_loss: 3.6109\n",
      "Epoch 47/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.8774 - loss: 0.3214\n",
      "Epoch 47: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.8286 - loss: 0.4011 - val_accuracy: 0.3594 - val_loss: 17.6599\n",
      "Epoch 48/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.7812 - loss: 0.4662\n",
      "Epoch 48: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7812 - loss: 0.4662 - val_accuracy: 0.3638 - val_loss: 19.1732\n",
      "Epoch 49/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8456 - loss: 0.3508\n",
      "Epoch 49: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.8591 - loss: 0.3365 - val_accuracy: 0.5223 - val_loss: 1.4930\n",
      "Epoch 50/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8906 - loss: 0.2837\n",
      "Epoch 50: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8906 - loss: 0.2837 - val_accuracy: 0.5156 - val_loss: 1.7998\n",
      "Epoch 51/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9122 - loss: 0.2586\n",
      "Epoch 51: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 281ms/step - accuracy: 0.8907 - loss: 0.2845 - val_accuracy: 0.6696 - val_loss: 0.8211\n",
      "Epoch 52/100\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 0.9375 - loss: 0.1937\n",
      "Epoch 52: val_loss did not improve from 0.17251\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9375 - loss: 0.1937 - val_accuracy: 0.6830 - val_loss: 0.8792\n",
      "Epoch 52: early stopping\n"
     ]
    }
   ],
   "source": [
    "# save the model architecture to json file for future use\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model3.keras\"), verbose=1,save_best_only=True)\n",
    "model.load_weights(str(MODELS_DIR / \"classifier-resnet-model3.keras\"))\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UNMYC2Ft8ww",
    "outputId": "6fe5f181-742b-42cb-dfab-2d1477575929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765233283.150377    4897 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.0996, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.9388 - loss: 0.1903   Batch 10: Loss = 0.2064, Accuracy = 0.9247\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9275 - loss: 0.2127   Batch 20: Loss = 0.2496, Accuracy = 0.9122\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 529ms/step - accuracy: 0.9228 - loss: 0.2225   Batch 30: Loss = 0.2414, Accuracy = 0.9136\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - accuracy: 0.9214 - loss: 0.2250   Batch 40: Loss = 0.2308, Accuracy = 0.9211\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.9215 - loss: 0.2253\n",
      "Epoch 1: val_loss improved from None to 34.44895, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 552ms/step - accuracy: 0.9226 - loss: 0.2273 - val_accuracy: 0.5156 - val_loss: 34.4490 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 2...\n",
      "Epoch 2/100\n",
      "   Batch 0: Loss = 0.1406, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.9531 - loss: 0.1406\n",
      "Epoch 2: val_loss did not improve from 34.44895\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1406 - val_accuracy: 0.4888 - val_loss: 43.8419 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 3...\n",
      "Epoch 3/100\n",
      "   Batch 0: Loss = 0.2024, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9360 - loss: 0.1776   Batch 10: Loss = 0.1632, Accuracy = 0.9418\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9387 - loss: 0.1859   Batch 20: Loss = 0.1996, Accuracy = 0.9397\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.9387 - loss: 0.1881   Batch 30: Loss = 0.1864, Accuracy = 0.9390\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.9383 - loss: 0.1885   Batch 40: Loss = 0.1947, Accuracy = 0.9344\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9380 - loss: 0.1889\n",
      "Epoch 3: val_loss improved from 34.44895 to 2.09986, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 317ms/step - accuracy: 0.9364 - loss: 0.1891 - val_accuracy: 0.7879 - val_loss: 2.0999 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 4...\n",
      "Epoch 4/100\n",
      "   Batch 0: Loss = 0.2292, Accuracy = 0.9062\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9062 - loss: 0.2292\n",
      "Epoch 4: val_loss improved from 2.09986 to 1.71090, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9062 - loss: 0.2292 - val_accuracy: 0.8103 - val_loss: 1.7109 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 5...\n",
      "Epoch 5/100\n",
      "   Batch 0: Loss = 0.0362, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 250ms/step - accuracy: 0.9605 - loss: 0.1475   Batch 10: Loss = 0.1693, Accuracy = 0.9418\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9504 - loss: 0.1590   Batch 20: Loss = 0.1705, Accuracy = 0.9397\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.9480 - loss: 0.1603   Batch 30: Loss = 0.1619, Accuracy = 0.9427\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9465 - loss: 0.1635   Batch 40: Loss = 0.1767, Accuracy = 0.9438\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9462 - loss: 0.1650\n",
      "Epoch 5: val_loss improved from 1.71090 to 0.97540, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 305ms/step - accuracy: 0.9415 - loss: 0.1818 - val_accuracy: 0.8058 - val_loss: 0.9754 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 6...\n",
      "Epoch 6/100\n",
      "   Batch 0: Loss = 0.1282, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 186ms/step - accuracy: 0.9375 - loss: 0.1282\n",
      "Epoch 6: val_loss did not improve from 0.97540\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1282 - val_accuracy: 0.7746 - val_loss: 1.5997 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 7...\n",
      "Epoch 7/100\n",
      "   Batch 0: Loss = 0.1976, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9284 - loss: 0.2533   Batch 10: Loss = 0.2426, Accuracy = 0.9261\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9254 - loss: 0.2434   Batch 20: Loss = 0.2200, Accuracy = 0.9226\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 266ms/step - accuracy: 0.9258 - loss: 0.2317   Batch 30: Loss = 0.1954, Accuracy = 0.9315\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.9275 - loss: 0.2227   Batch 40: Loss = 0.1953, Accuracy = 0.9318\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9279 - loss: 0.2202\n",
      "Epoch 7: val_loss did not improve from 0.97540\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 305ms/step - accuracy: 0.9325 - loss: 0.1946 - val_accuracy: 0.7411 - val_loss: 4.6237 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 8...\n",
      "Epoch 8/100\n",
      "   Batch 0: Loss = 2.1161, Accuracy = 0.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2.1161\n",
      "Epoch 8: val_loss did not improve from 0.97540\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0000e+00 - loss: 2.1161 - val_accuracy: 0.7433 - val_loss: 4.5143 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 9...\n",
      "Epoch 9/100\n",
      "   Batch 0: Loss = 0.1176, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9603 - loss: 0.1492   Batch 10: Loss = 0.1651, Accuracy = 0.9517\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - accuracy: 0.9549 - loss: 0.1583   Batch 20: Loss = 0.1667, Accuracy = 0.9500\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9537 - loss: 0.1593   Batch 30: Loss = 0.1537, Accuracy = 0.9542\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9542 - loss: 0.1577   Batch 40: Loss = 0.1505, Accuracy = 0.9567\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9544 - loss: 0.1570\n",
      "Epoch 9: val_loss did not improve from 0.97540\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.9571 - loss: 0.1517 - val_accuracy: 0.7299 - val_loss: 15.5595 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 10...\n",
      "Epoch 10/100\n",
      "   Batch 0: Loss = 0.2026, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.9375 - loss: 0.2026\n",
      "Epoch 10: val_loss did not improve from 0.97540\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9375 - loss: 0.2026 - val_accuracy: 0.7232 - val_loss: 13.7497 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 11...\n",
      "Epoch 11/100\n",
      "   Batch 0: Loss = 0.2235, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.9463 - loss: 0.1776   Batch 10: Loss = 0.1333, Accuracy = 0.9560\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - accuracy: 0.9527 - loss: 0.1542   Batch 20: Loss = 0.1284, Accuracy = 0.9633\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9561 - loss: 0.1443   Batch 30: Loss = 0.1209, Accuracy = 0.9630\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 0.9578 - loss: 0.1386   Batch 40: Loss = 0.1246, Accuracy = 0.9602\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9579 - loss: 0.1375\n",
      "Epoch 11: val_loss improved from 0.97540 to 0.83242, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 316ms/step - accuracy: 0.9586 - loss: 0.1326 - val_accuracy: 0.9018 - val_loss: 0.8324 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 12...\n",
      "Epoch 12/100\n",
      "   Batch 0: Loss = 0.1643, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 186ms/step - accuracy: 0.9688 - loss: 0.1643\n",
      "Epoch 12: val_loss did not improve from 0.83242\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.1643 - val_accuracy: 0.8951 - val_loss: 1.1571 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 13...\n",
      "Epoch 13/100\n",
      "   Batch 0: Loss = 0.0914, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9671 - loss: 0.1135   Batch 10: Loss = 0.1085, Accuracy = 0.9673\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9701 - loss: 0.1044   Batch 20: Loss = 0.0922, Accuracy = 0.9742\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9708 - loss: 0.1037   Batch 30: Loss = 0.1097, Accuracy = 0.9688\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9701 - loss: 0.1049   Batch 40: Loss = 0.1083, Accuracy = 0.9676\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9700 - loss: 0.1050\n",
      "Epoch 13: val_loss improved from 0.83242 to 0.15691, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model4.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - accuracy: 0.9691 - loss: 0.1068 - val_accuracy: 0.9420 - val_loss: 0.1569 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 14...\n",
      "Epoch 14/100\n",
      "   Batch 0: Loss = 0.1098, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.9531 - loss: 0.1098\n",
      "Epoch 14: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1098 - val_accuracy: 0.9509 - val_loss: 0.2220 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 15...\n",
      "Epoch 15/100\n",
      "   Batch 0: Loss = 0.1151, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.9820 - loss: 0.0880   Batch 10: Loss = 0.0835, Accuracy = 0.9773\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9799 - loss: 0.0867   Batch 20: Loss = 0.1003, Accuracy = 0.9784\n",
      "\u001b[1m29/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.9784 - loss: 0.0908   Batch 30: Loss = 0.0992, Accuracy = 0.9735\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.9769 - loss: 0.0932   Batch 40: Loss = 0.1053, Accuracy = 0.9688\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9762 - loss: 0.0943\n",
      "Epoch 15: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 298ms/step - accuracy: 0.9688 - loss: 0.1041 - val_accuracy: 0.7344 - val_loss: 0.8541 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 16...\n",
      "Epoch 16/100\n",
      "   Batch 0: Loss = 0.0469, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9844 - loss: 0.0469\n",
      "Epoch 16: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.0469 - val_accuracy: 0.7143 - val_loss: 1.1186 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 17...\n",
      "Epoch 17/100\n",
      "   Batch 0: Loss = 0.0927, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9613 - loss: 0.1017   Batch 10: Loss = 0.0964, Accuracy = 0.9602\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9590 - loss: 0.1053   Batch 20: Loss = 0.1141, Accuracy = 0.9561\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9574 - loss: 0.1112   Batch 30: Loss = 0.1255, Accuracy = 0.9542\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9564 - loss: 0.1160   Batch 40: Loss = 0.1279, Accuracy = 0.9547\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9562 - loss: 0.1171\n",
      "Epoch 17: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9521 - loss: 0.1299 - val_accuracy: 0.8259 - val_loss: 0.4231 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 18...\n",
      "Epoch 18/100\n",
      "   Batch 0: Loss = 0.0648, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9844 - loss: 0.0648\n",
      "Epoch 18: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.0648 - val_accuracy: 0.8371 - val_loss: 0.4006 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 19...\n",
      "Epoch 19/100\n",
      "   Batch 0: Loss = 0.0585, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9666 - loss: 0.0918   Batch 10: Loss = 0.1131, Accuracy = 0.9545\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9616 - loss: 0.1053   Batch 20: Loss = 0.1238, Accuracy = 0.9583\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9608 - loss: 0.1103   Batch 30: Loss = 0.1166, Accuracy = 0.9594\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9604 - loss: 0.1124   Batch 40: Loss = 0.1191, Accuracy = 0.9594\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9603 - loss: 0.1131\n",
      "Epoch 19: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 296ms/step - accuracy: 0.9600 - loss: 0.1183 - val_accuracy: 0.8973 - val_loss: 0.2952 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 20...\n",
      "Epoch 20/100\n",
      "   Batch 0: Loss = 0.0653, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 184ms/step - accuracy: 0.9844 - loss: 0.0653\n",
      "Epoch 20: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0653 - val_accuracy: 0.8996 - val_loss: 0.2453 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 21...\n",
      "Epoch 21/100\n",
      "   Batch 0: Loss = 0.0659, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9665 - loss: 0.0878   Batch 10: Loss = 0.1166, Accuracy = 0.9631\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9632 - loss: 0.1046   Batch 20: Loss = 0.1147, Accuracy = 0.9621\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9631 - loss: 0.1079   Batch 30: Loss = 0.1157, Accuracy = 0.9630\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9627 - loss: 0.1102   Batch 40: Loss = 0.1211, Accuracy = 0.9606\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9625 - loss: 0.1112\n",
      "Epoch 21: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9604 - loss: 0.1213 - val_accuracy: 0.9375 - val_loss: 0.2334 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 22...\n",
      "Epoch 22/100\n",
      "   Batch 0: Loss = 0.1020, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.9688 - loss: 0.1020\n",
      "Epoch 22: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.1020 - val_accuracy: 0.9308 - val_loss: 0.1909 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 23...\n",
      "Epoch 23/100\n",
      "   Batch 0: Loss = 0.1467, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.9402 - loss: 0.1308   Batch 10: Loss = 0.1209, Accuracy = 0.9501\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9473 - loss: 0.1263   Batch 20: Loss = 0.1343, Accuracy = 0.9524\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.9498 - loss: 0.1268   Batch 30: Loss = 0.1233, Accuracy = 0.9568\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9519 - loss: 0.1249   Batch 40: Loss = 0.1148, Accuracy = 0.9602\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9526 - loss: 0.1241\n",
      "Epoch 23: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 290ms/step - accuracy: 0.9604 - loss: 0.1168 - val_accuracy: 0.9420 - val_loss: 0.1755 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 24...\n",
      "Epoch 24/100\n",
      "   Batch 0: Loss = 0.1995, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9531 - loss: 0.1995\n",
      "Epoch 24: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1995 - val_accuracy: 0.9420 - val_loss: 0.1781 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 25...\n",
      "Epoch 25/100\n",
      "   Batch 0: Loss = 0.0738, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9670 - loss: 0.0876   Batch 10: Loss = 0.1039, Accuracy = 0.9645\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - accuracy: 0.9644 - loss: 0.0969   Batch 20: Loss = 0.1079, Accuracy = 0.9625\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9640 - loss: 0.1024   Batch 30: Loss = 0.1129, Accuracy = 0.9630\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9641 - loss: 0.1044   Batch 40: Loss = 0.1086, Accuracy = 0.9656\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9642 - loss: 0.1048\n",
      "Epoch 25: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9659 - loss: 0.1090 - val_accuracy: 0.9375 - val_loss: 0.1864 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 26...\n",
      "Epoch 26/100\n",
      "   Batch 0: Loss = 0.1185, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9531 - loss: 0.1185\n",
      "Epoch 26: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1185 - val_accuracy: 0.9464 - val_loss: 0.1800 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 27...\n",
      "Epoch 27/100\n",
      "   Batch 0: Loss = 0.0335, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9605 - loss: 0.1357   Batch 10: Loss = 0.1514, Accuracy = 0.9602\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - accuracy: 0.9610 - loss: 0.1383   Batch 20: Loss = 0.1327, Accuracy = 0.9625\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9618 - loss: 0.1347   Batch 30: Loss = 0.1299, Accuracy = 0.9625\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9620 - loss: 0.1329   Batch 40: Loss = 0.1267, Accuracy = 0.9621\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9620 - loss: 0.1323\n",
      "Epoch 27: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9622 - loss: 0.1267 - val_accuracy: 0.9487 - val_loss: 0.1659 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 28...\n",
      "Epoch 28/100\n",
      "   Batch 0: Loss = 0.1457, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.9531 - loss: 0.1457\n",
      "Epoch 28: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1457 - val_accuracy: 0.9420 - val_loss: 0.1861 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 29...\n",
      "Epoch 29/100\n",
      "   Batch 0: Loss = 0.1016, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9626 - loss: 0.1058   Batch 10: Loss = 0.1127, Accuracy = 0.9602\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.9615 - loss: 0.1146   Batch 20: Loss = 0.1324, Accuracy = 0.9606\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 266ms/step - accuracy: 0.9613 - loss: 0.1189   Batch 30: Loss = 0.1222, Accuracy = 0.9622\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.9615 - loss: 0.1196   Batch 40: Loss = 0.1182, Accuracy = 0.9625\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9616 - loss: 0.1195\n",
      "Epoch 29: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 296ms/step - accuracy: 0.9626 - loss: 0.1198 - val_accuracy: 0.9442 - val_loss: 0.1770 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 30...\n",
      "Epoch 30/100\n",
      "   Batch 0: Loss = 0.0821, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9531 - loss: 0.0821\n",
      "Epoch 30: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.0821 - val_accuracy: 0.9531 - val_loss: 0.1805 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 31...\n",
      "Epoch 31/100\n",
      "   Batch 0: Loss = 0.0786, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9719 - loss: 0.0826   Batch 10: Loss = 0.0991, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9695 - loss: 0.0924   Batch 20: Loss = 0.1061, Accuracy = 0.9650\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9681 - loss: 0.0969   Batch 30: Loss = 0.1080, Accuracy = 0.9642\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9670 - loss: 0.0996   Batch 40: Loss = 0.1078, Accuracy = 0.9637\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9667 - loss: 0.1004\n",
      "Epoch 31: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9633 - loss: 0.1089 - val_accuracy: 0.9464 - val_loss: 0.1773 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 32...\n",
      "Epoch 32/100\n",
      "   Batch 0: Loss = 0.1071, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9375 - loss: 0.1071\n",
      "Epoch 32: val_loss did not improve from 0.15691\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1071 - val_accuracy: 0.9531 - val_loss: 0.1574 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 33...\n",
      "Epoch 33/100\n",
      "   Batch 0: Loss = 0.0725, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9595 - loss: 0.1077   Batch 10: Loss = 0.1098, Accuracy = 0.9616\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - accuracy: 0.9610 - loss: 0.1099   Batch 20: Loss = 0.1094, Accuracy = 0.9625\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - accuracy: 0.9612 - loss: 0.1101   Batch 30: Loss = 0.1053, Accuracy = 0.9641\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.9616 - loss: 0.1102   Batch 40: Loss = 0.1099, Accuracy = 0.9621\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9616 - loss: 0.1104\n",
      "Epoch 33: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 295ms/step - accuracy: 0.9611 - loss: 0.1145 - val_accuracy: 0.9576 - val_loss: 0.1634 - learning_rate: 1.0000e-07\n",
      "Epoch 33: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(str(MODELS_DIR / \"classifier-resnet-model3.keras\"))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model4.keras\"), verbose=1,save_best_only=True)\n",
    "\n",
    "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping,lr_reduce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eawO2HWyDcdM"
   },
   "source": [
    "MINI CHALLENGE #5:\n",
    "- Change the network architecture by adding more/less dense layers, neurons or dropout.\n",
    "- print out the model summary and compare the total number of trainable parameters between the original and new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yItmXPFXDsOc",
    "outputId": "01dbdbf5-df89-43e6-ed24-f1d6518adb52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765233575.056599    4899 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.0519, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10s\u001b[0m 298ms/step - accuracy: 0.9392 - loss: 0.1986   Batch 10: Loss = 0.1929, Accuracy = 0.9418\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9411 - loss: 0.1897   Batch 20: Loss = 0.1776, Accuracy = 0.9438\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 573ms/step - accuracy: 0.9420 - loss: 0.1855   Batch 30: Loss = 0.1822, Accuracy = 0.9443\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 491ms/step - accuracy: 0.9424 - loss: 0.1839   Batch 40: Loss = 0.1794, Accuracy = 0.9414\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - accuracy: 0.9423 - loss: 0.1834\n",
      "Epoch 1: val_loss improved from None to 16.41238, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 583ms/step - accuracy: 0.9415 - loss: 0.1790 - val_accuracy: 0.6741 - val_loss: 16.4124 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 2...\n",
      "Epoch 2/100\n",
      "   Batch 0: Loss = 0.1425, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.9375 - loss: 0.1425\n",
      "Epoch 2: val_loss did not improve from 16.41238\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9375 - loss: 0.1425 - val_accuracy: 0.6473 - val_loss: 18.5398 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 3...\n",
      "Epoch 3/100\n",
      "   Batch 0: Loss = 0.2064, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9274 - loss: 0.2112   Batch 10: Loss = 0.1757, Accuracy = 0.9389\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9364 - loss: 0.1997   Batch 20: Loss = 0.1796, Accuracy = 0.9494\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 258ms/step - accuracy: 0.9397 - loss: 0.1953   Batch 30: Loss = 0.1905, Accuracy = 0.9433\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.9412 - loss: 0.1916   Batch 40: Loss = 0.1726, Accuracy = 0.9477\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9419 - loss: 0.1899\n",
      "Epoch 3: val_loss improved from 16.41238 to 0.30678, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 313ms/step - accuracy: 0.9484 - loss: 0.1722 - val_accuracy: 0.9308 - val_loss: 0.3068 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 4...\n",
      "Epoch 4/100\n",
      "   Batch 0: Loss = 0.0946, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 189ms/step - accuracy: 0.9375 - loss: 0.0946\n",
      "Epoch 4: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9375 - loss: 0.0946 - val_accuracy: 0.9219 - val_loss: 0.3297 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 5...\n",
      "Epoch 5/100\n",
      "   Batch 0: Loss = 0.0910, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.9578 - loss: 0.1481   Batch 10: Loss = 0.1526, Accuracy = 0.9560\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9586 - loss: 0.1447   Batch 20: Loss = 0.1239, Accuracy = 0.9641\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - accuracy: 0.9608 - loss: 0.1357   Batch 30: Loss = 0.1164, Accuracy = 0.9651\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9618 - loss: 0.1310   Batch 40: Loss = 0.1208, Accuracy = 0.9637\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9619 - loss: 0.1302\n",
      "Epoch 5: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.9633 - loss: 0.1240 - val_accuracy: 0.8750 - val_loss: 0.4436 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 6...\n",
      "Epoch 6/100\n",
      "   Batch 0: Loss = 0.1061, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.9531 - loss: 0.1061\n",
      "Epoch 6: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1061 - val_accuracy: 0.8862 - val_loss: 0.3961 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 7...\n",
      "Epoch 7/100\n",
      "   Batch 0: Loss = 0.0452, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9662 - loss: 0.1684   Batch 10: Loss = 0.1483, Accuracy = 0.9574\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 242ms/step - accuracy: 0.9639 - loss: 0.1533   Batch 20: Loss = 0.1287, Accuracy = 0.9613\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9622 - loss: 0.1471   Batch 30: Loss = 0.1392, Accuracy = 0.9563\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 0.9599 - loss: 0.1468   Batch 40: Loss = 0.1492, Accuracy = 0.9500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9590 - loss: 0.1472\n",
      "Epoch 7: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 296ms/step - accuracy: 0.9510 - loss: 0.1512 - val_accuracy: 0.5402 - val_loss: 19.2833 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 8...\n",
      "Epoch 8/100\n",
      "   Batch 0: Loss = 0.1276, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.9531 - loss: 0.1276\n",
      "Epoch 8: val_loss did not improve from 0.30678\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1276 - val_accuracy: 0.5357 - val_loss: 20.3066 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 9...\n",
      "Epoch 9/100\n",
      "   Batch 0: Loss = 0.3676, Accuracy = 0.8750\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9432 - loss: 0.1883   Batch 10: Loss = 0.1299, Accuracy = 0.9673\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9527 - loss: 0.1622   Batch 20: Loss = 0.1322, Accuracy = 0.9613\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 254ms/step - accuracy: 0.9546 - loss: 0.1553   Batch 30: Loss = 0.1445, Accuracy = 0.9567\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.9548 - loss: 0.1526   Batch 40: Loss = 0.1446, Accuracy = 0.9555\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9549 - loss: 0.1517\n",
      "Epoch 9: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.9560 - loss: 0.1423 - val_accuracy: 0.8728 - val_loss: 0.8927 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 10...\n",
      "Epoch 10/100\n",
      "   Batch 0: Loss = 0.1489, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9375 - loss: 0.1489\n",
      "Epoch 10: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1489 - val_accuracy: 0.8527 - val_loss: 0.9534 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 11...\n",
      "Epoch 11/100\n",
      "   Batch 0: Loss = 0.1528, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.9412 - loss: 0.1445   Batch 10: Loss = 0.1320, Accuracy = 0.9531\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 229ms/step - accuracy: 0.9500 - loss: 0.1318   Batch 20: Loss = 0.1114, Accuracy = 0.9617\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9551 - loss: 0.1226   Batch 30: Loss = 0.1011, Accuracy = 0.9672\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9578 - loss: 0.1177   Batch 40: Loss = 0.1037, Accuracy = 0.9656\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9585 - loss: 0.1165\n",
      "Epoch 11: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 295ms/step - accuracy: 0.9648 - loss: 0.1048 - val_accuracy: 0.9286 - val_loss: 0.3513 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 12...\n",
      "Epoch 12/100\n",
      "   Batch 0: Loss = 0.0672, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9688 - loss: 0.0672\n",
      "Epoch 12: val_loss did not improve from 0.30678\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0672 - val_accuracy: 0.9308 - val_loss: 0.3346 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 13...\n",
      "Epoch 13/100\n",
      "   Batch 0: Loss = 0.0501, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9788 - loss: 0.0695   Batch 10: Loss = 0.0787, Accuracy = 0.9759\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9729 - loss: 0.0834   Batch 20: Loss = 0.1054, Accuracy = 0.9635\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - accuracy: 0.9697 - loss: 0.0907   Batch 30: Loss = 0.1016, Accuracy = 0.9630\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9679 - loss: 0.0937   Batch 40: Loss = 0.1030, Accuracy = 0.9613\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9673 - loss: 0.0944\n",
      "Epoch 13: val_loss improved from 0.30678 to 0.17932, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 304ms/step - accuracy: 0.9622 - loss: 0.0996 - val_accuracy: 0.9531 - val_loss: 0.1793 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 14...\n",
      "Epoch 14/100\n",
      "   Batch 0: Loss = 0.1858, Accuracy = 0.9062\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.9062 - loss: 0.1858\n",
      "Epoch 14: val_loss improved from 0.17932 to 0.17872, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9062 - loss: 0.1858 - val_accuracy: 0.9509 - val_loss: 0.1787 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 15...\n",
      "Epoch 15/100\n",
      "   Batch 0: Loss = 0.1203, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.9699 - loss: 0.0959   Batch 10: Loss = 0.1070, Accuracy = 0.9673\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9687 - loss: 0.1045   Batch 20: Loss = 0.1056, Accuracy = 0.9680\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.9684 - loss: 0.1049   Batch 30: Loss = 0.1044, Accuracy = 0.9672\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9682 - loss: 0.1046   Batch 40: Loss = 0.1012, Accuracy = 0.9676\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9681 - loss: 0.1041\n",
      "Epoch 15: val_loss improved from 0.17872 to 0.16649, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 318ms/step - accuracy: 0.9680 - loss: 0.0994 - val_accuracy: 0.9464 - val_loss: 0.1665 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 16...\n",
      "Epoch 16/100\n",
      "   Batch 0: Loss = 0.0542, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.9844 - loss: 0.0542\n",
      "Epoch 16: val_loss improved from 0.16649 to 0.14796, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9844 - loss: 0.0542 - val_accuracy: 0.9688 - val_loss: 0.1480 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 17...\n",
      "Epoch 17/100\n",
      "   Batch 0: Loss = 0.0454, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.9805 - loss: 0.0776   Batch 10: Loss = 0.0955, Accuracy = 0.9716\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.9762 - loss: 0.0868   Batch 20: Loss = 0.0907, Accuracy = 0.9740\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - accuracy: 0.9751 - loss: 0.0875   Batch 30: Loss = 0.0858, Accuracy = 0.9733\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 0.9750 - loss: 0.0869   Batch 40: Loss = 0.0863, Accuracy = 0.9741\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9749 - loss: 0.0869\n",
      "Epoch 17: val_loss improved from 0.14796 to 0.14581, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 315ms/step - accuracy: 0.9738 - loss: 0.0886 - val_accuracy: 0.9576 - val_loss: 0.1458 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 18...\n",
      "Epoch 18/100\n",
      "   Batch 0: Loss = 0.0683, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 188ms/step - accuracy: 0.9531 - loss: 0.0683\n",
      "Epoch 18: val_loss improved from 0.14581 to 0.13661, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9531 - loss: 0.0683 - val_accuracy: 0.9710 - val_loss: 0.1366 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 19...\n",
      "Epoch 19/100\n",
      "   Batch 0: Loss = 0.1115, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 247ms/step - accuracy: 0.9663 - loss: 0.0895   Batch 10: Loss = 0.1008, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - accuracy: 0.9681 - loss: 0.0932   Batch 20: Loss = 0.0882, Accuracy = 0.9742\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9703 - loss: 0.0920   Batch 30: Loss = 0.0885, Accuracy = 0.9755\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9716 - loss: 0.0905   Batch 40: Loss = 0.0872, Accuracy = 0.9746\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9719 - loss: 0.0902\n",
      "Epoch 19: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9742 - loss: 0.0868 - val_accuracy: 0.9665 - val_loss: 0.1424 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 20...\n",
      "Epoch 20/100\n",
      "   Batch 0: Loss = 0.0878, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.9688 - loss: 0.0878\n",
      "Epoch 20: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9688 - loss: 0.0878 - val_accuracy: 0.9554 - val_loss: 0.1515 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 21...\n",
      "Epoch 21/100\n",
      "   Batch 0: Loss = 0.0470, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.9804 - loss: 0.0562   Batch 10: Loss = 0.0535, Accuracy = 0.9815\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9802 - loss: 0.0562   Batch 20: Loss = 0.0638, Accuracy = 0.9784\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.9788 - loss: 0.0602   Batch 30: Loss = 0.0731, Accuracy = 0.9753\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9774 - loss: 0.0641   Batch 40: Loss = 0.0766, Accuracy = 0.9726\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9769 - loss: 0.0654\n",
      "Epoch 21: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 291ms/step - accuracy: 0.9719 - loss: 0.0792 - val_accuracy: 0.9598 - val_loss: 0.1547 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 22...\n",
      "Epoch 22/100\n",
      "   Batch 0: Loss = 0.0041, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 22: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9621 - val_loss: 0.1539 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 23...\n",
      "Epoch 23/100\n",
      "   Batch 0: Loss = 0.0404, Accuracy = 0.9844\n",
      "\u001b[1m 9/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9735 - loss: 0.0573   Batch 10: Loss = 0.0827, Accuracy = 0.9672\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9695 - loss: 0.0730   Batch 20: Loss = 0.0824, Accuracy = 0.9680\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - accuracy: 0.9695 - loss: 0.0754   Batch 30: Loss = 0.0793, Accuracy = 0.9693\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9695 - loss: 0.0761   Batch 40: Loss = 0.0778, Accuracy = 0.9707\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9696 - loss: 0.0763\n",
      "Epoch 23: val_loss did not improve from 0.13661\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.9709 - loss: 0.0795 - val_accuracy: 0.9576 - val_loss: 0.1561 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 24...\n",
      "Epoch 24/100\n",
      "   Batch 0: Loss = 0.0454, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 186ms/step - accuracy: 0.9844 - loss: 0.0454\n",
      "Epoch 24: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9844 - loss: 0.0454 - val_accuracy: 0.9576 - val_loss: 0.1500 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 25...\n",
      "Epoch 25/100\n",
      "   Batch 0: Loss = 0.1437, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9641 - loss: 0.0948   Batch 10: Loss = 0.0798, Accuracy = 0.9702\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9680 - loss: 0.0861   Batch 20: Loss = 0.0767, Accuracy = 0.9727\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - accuracy: 0.9702 - loss: 0.0816   Batch 30: Loss = 0.0736, Accuracy = 0.9740\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9711 - loss: 0.0794   Batch 40: Loss = 0.0727, Accuracy = 0.9734\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9713 - loss: 0.0787\n",
      "Epoch 25: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 287ms/step - accuracy: 0.9738 - loss: 0.0710 - val_accuracy: 0.9621 - val_loss: 0.1473 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 26...\n",
      "Epoch 26/100\n",
      "   Batch 0: Loss = 0.0355, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0355\n",
      "Epoch 26: val_loss did not improve from 0.13661\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.9643 - val_loss: 0.1640 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 27...\n",
      "Epoch 27/100\n",
      "   Batch 0: Loss = 0.0581, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9752 - loss: 0.0693   Batch 10: Loss = 0.0686, Accuracy = 0.9787\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9743 - loss: 0.0754   Batch 20: Loss = 0.0815, Accuracy = 0.9717\n",
      "\u001b[1m29/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.9733 - loss: 0.0785   Batch 30: Loss = 0.0840, Accuracy = 0.9714\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9731 - loss: 0.0791   Batch 40: Loss = 0.0829, Accuracy = 0.9727\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9732 - loss: 0.0793\n",
      "Epoch 27: val_loss improved from 0.13661 to 0.13417, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 305ms/step - accuracy: 0.9735 - loss: 0.0813 - val_accuracy: 0.9665 - val_loss: 0.1342 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 28...\n",
      "Epoch 28/100\n",
      "   Batch 0: Loss = 0.0972, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9688 - loss: 0.0972\n",
      "Epoch 28: val_loss did not improve from 0.13417\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0972 - val_accuracy: 0.9598 - val_loss: 0.1477 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 29...\n",
      "Epoch 29/100\n",
      "   Batch 0: Loss = 0.0695, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.9820 - loss: 0.0772   Batch 10: Loss = 0.1040, Accuracy = 0.9750\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9788 - loss: 0.0859   Batch 20: Loss = 0.0876, Accuracy = 0.9758\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.9774 - loss: 0.0867   Batch 30: Loss = 0.0891, Accuracy = 0.9724\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.9761 - loss: 0.0873   Batch 40: Loss = 0.0859, Accuracy = 0.9719\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9757 - loss: 0.0870\n",
      "Epoch 29: val_loss improved from 0.13417 to 0.12633, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 321ms/step - accuracy: 0.9728 - loss: 0.0832 - val_accuracy: 0.9665 - val_loss: 0.1263 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 30...\n",
      "Epoch 30/100\n",
      "   Batch 0: Loss = 0.0436, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.9844 - loss: 0.0436\n",
      "Epoch 30: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.0436 - val_accuracy: 0.9754 - val_loss: 0.1280 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 31...\n",
      "Epoch 31/100\n",
      "   Batch 0: Loss = 0.0903, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9629 - loss: 0.1077   Batch 10: Loss = 0.1023, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - accuracy: 0.9672 - loss: 0.1022   Batch 20: Loss = 0.0919, Accuracy = 0.9719\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9693 - loss: 0.0970   Batch 30: Loss = 0.0813, Accuracy = 0.9755\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9711 - loss: 0.0931   Batch 40: Loss = 0.0839, Accuracy = 0.9766\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9715 - loss: 0.0923\n",
      "Epoch 31: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 287ms/step - accuracy: 0.9753 - loss: 0.0839 - val_accuracy: 0.9576 - val_loss: 0.1603 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 32...\n",
      "Epoch 32/100\n",
      "   Batch 0: Loss = 0.0184, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 32: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.9688 - val_loss: 0.1411 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 33...\n",
      "Epoch 33/100\n",
      "   Batch 0: Loss = 0.0645, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9757 - loss: 0.0731   Batch 10: Loss = 0.0739, Accuracy = 0.9673\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.9727 - loss: 0.0721   Batch 20: Loss = 0.0781, Accuracy = 0.9717\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.9731 - loss: 0.0738   Batch 30: Loss = 0.0761, Accuracy = 0.9750\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.9736 - loss: 0.0750   Batch 40: Loss = 0.0789, Accuracy = 0.9758\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9738 - loss: 0.0753\n",
      "Epoch 33: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9757 - loss: 0.0780 - val_accuracy: 0.9576 - val_loss: 0.1670 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 34...\n",
      "Epoch 34/100\n",
      "   Batch 0: Loss = 0.0376, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0376\n",
      "Epoch 34: val_loss did not improve from 0.12633\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.9665 - val_loss: 0.1512 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 35...\n",
      "Epoch 35/100\n",
      "   Batch 0: Loss = 0.0979, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9640 - loss: 0.1680   Batch 10: Loss = 0.1226, Accuracy = 0.9673\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - accuracy: 0.9660 - loss: 0.1385   Batch 20: Loss = 0.0972, Accuracy = 0.9688\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - accuracy: 0.9673 - loss: 0.1224   Batch 30: Loss = 0.0826, Accuracy = 0.9719\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9688 - loss: 0.1122   Batch 40: Loss = 0.0817, Accuracy = 0.9738\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9693 - loss: 0.1094\n",
      "Epoch 35: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 291ms/step - accuracy: 0.9749 - loss: 0.0815 - val_accuracy: 0.9665 - val_loss: 0.1474 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 36...\n",
      "Epoch 36/100\n",
      "   Batch 0: Loss = 0.0814, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.9688 - loss: 0.0814\n",
      "Epoch 36: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9688 - loss: 0.0814 - val_accuracy: 0.9621 - val_loss: 0.1606 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 37...\n",
      "Epoch 37/100\n",
      "   Batch 0: Loss = 0.0638, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.9663 - loss: 0.0857   Batch 10: Loss = 0.0812, Accuracy = 0.9744\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.9708 - loss: 0.0817   Batch 20: Loss = 0.0761, Accuracy = 0.9750\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.9722 - loss: 0.0803   Batch 30: Loss = 0.0847, Accuracy = 0.9735\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.9724 - loss: 0.0812   Batch 40: Loss = 0.0801, Accuracy = 0.9738\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9725 - loss: 0.0810\n",
      "Epoch 37: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9738 - loss: 0.0783 - val_accuracy: 0.9576 - val_loss: 0.1368 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 38...\n",
      "Epoch 38/100\n",
      "   Batch 0: Loss = 0.1168, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.9531 - loss: 0.1168\n",
      "Epoch 38: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1168 - val_accuracy: 0.9621 - val_loss: 0.1615 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 39...\n",
      "Epoch 39/100\n",
      "   Batch 0: Loss = 0.0540, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9796 - loss: 0.0679   Batch 10: Loss = 0.0761, Accuracy = 0.9759\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9783 - loss: 0.0695   Batch 20: Loss = 0.0715, Accuracy = 0.9769\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.9780 - loss: 0.0696   Batch 30: Loss = 0.0719, Accuracy = 0.9768\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9773 - loss: 0.0712   Batch 40: Loss = 0.0827, Accuracy = 0.9742\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9770 - loss: 0.0723\n",
      "Epoch 39: val_loss did not improve from 0.12633\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 286ms/step - accuracy: 0.9738 - loss: 0.0854 - val_accuracy: 0.9643 - val_loss: 0.1555 - learning_rate: 1.0000e-06\n",
      "\n",
      "ğŸš€ Starting Epoch 40...\n",
      "Epoch 40/100\n",
      "   Batch 0: Loss = 0.0887, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.9688 - loss: 0.0887\n",
      "Epoch 40: val_loss did not improve from 0.12633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0887 - val_accuracy: 0.9665 - val_loss: 0.1269 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 41...\n",
      "Epoch 41/100\n",
      "   Batch 0: Loss = 0.0306, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9920 - loss: 0.0446   Batch 10: Loss = 0.0742, Accuracy = 0.9815\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9874 - loss: 0.0569   Batch 20: Loss = 0.0656, Accuracy = 0.9821\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 250ms/step - accuracy: 0.9843 - loss: 0.0622   Batch 30: Loss = 0.0756, Accuracy = 0.9768\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.9825 - loss: 0.0653   Batch 40: Loss = 0.0734, Accuracy = 0.9770\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9820 - loss: 0.0660\n",
      "Epoch 41: val_loss improved from 0.12633 to 0.12591, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 318ms/step - accuracy: 0.9775 - loss: 0.0743 - val_accuracy: 0.9598 - val_loss: 0.1259 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 42...\n",
      "Epoch 42/100\n",
      "   Batch 0: Loss = 0.0448, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 186ms/step - accuracy: 0.9688 - loss: 0.0448\n",
      "Epoch 42: val_loss did not improve from 0.12591\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0448 - val_accuracy: 0.9688 - val_loss: 0.1429 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 43...\n",
      "Epoch 43/100\n",
      "   Batch 0: Loss = 0.0729, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.9743 - loss: 0.0760   Batch 10: Loss = 0.0725, Accuracy = 0.9797\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9754 - loss: 0.0774   Batch 20: Loss = 0.0774, Accuracy = 0.9774\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9753 - loss: 0.0786   Batch 30: Loss = 0.0848, Accuracy = 0.9719\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9747 - loss: 0.0794   Batch 40: Loss = 0.0805, Accuracy = 0.9734\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9746 - loss: 0.0795\n",
      "Epoch 43: val_loss did not improve from 0.12591\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9742 - loss: 0.0802 - val_accuracy: 0.9643 - val_loss: 0.1315 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 44...\n",
      "Epoch 44/100\n",
      "   Batch 0: Loss = 0.1107, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.9844 - loss: 0.1107\n",
      "Epoch 44: val_loss did not improve from 0.12591\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.1107 - val_accuracy: 0.9598 - val_loss: 0.1545 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 45...\n",
      "Epoch 45/100\n",
      "   Batch 0: Loss = 0.1390, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9674 - loss: 0.0968   Batch 10: Loss = 0.0831, Accuracy = 0.9744\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - accuracy: 0.9700 - loss: 0.0927   Batch 20: Loss = 0.0811, Accuracy = 0.9742\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9717 - loss: 0.0887   Batch 30: Loss = 0.0820, Accuracy = 0.9745\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9723 - loss: 0.0869   Batch 40: Loss = 0.0800, Accuracy = 0.9742\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9725 - loss: 0.0864\n",
      "Epoch 45: val_loss did not improve from 0.12591\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - accuracy: 0.9731 - loss: 0.0832 - val_accuracy: 0.9621 - val_loss: 0.1521 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 46...\n",
      "Epoch 46/100\n",
      "   Batch 0: Loss = 0.0214, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0214\n",
      "Epoch 46: val_loss did not improve from 0.12591\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.9621 - val_loss: 0.1317 - learning_rate: 1.0000e-07\n",
      "\n",
      "ğŸš€ Starting Epoch 47...\n",
      "Epoch 47/100\n",
      "   Batch 0: Loss = 0.2139, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9643 - loss: 0.1121   Batch 10: Loss = 0.0753, Accuracy = 0.9787\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9725 - loss: 0.0906   Batch 20: Loss = 0.0681, Accuracy = 0.9805\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9743 - loss: 0.0872   Batch 30: Loss = 0.0860, Accuracy = 0.9771\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9752 - loss: 0.0863   Batch 40: Loss = 0.0802, Accuracy = 0.9781\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9754 - loss: 0.0858\n",
      "Epoch 47: val_loss improved from 0.12591 to 0.11299, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.9778 - loss: 0.0822 - val_accuracy: 0.9665 - val_loss: 0.1130 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 48...\n",
      "Epoch 48/100\n",
      "   Batch 0: Loss = 0.0995, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.9688 - loss: 0.0995\n",
      "Epoch 48: val_loss did not improve from 0.11299\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0995 - val_accuracy: 0.9665 - val_loss: 0.1591 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 49...\n",
      "Epoch 49/100\n",
      "   Batch 0: Loss = 0.0271, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 247ms/step - accuracy: 0.9758 - loss: 0.0815   Batch 10: Loss = 0.0956, Accuracy = 0.9659\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9699 - loss: 0.0892   Batch 20: Loss = 0.0996, Accuracy = 0.9643\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.9686 - loss: 0.0914   Batch 30: Loss = 0.0950, Accuracy = 0.9672\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9688 - loss: 0.0909   Batch 40: Loss = 0.0868, Accuracy = 0.9707\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9690 - loss: 0.0904\n",
      "Epoch 49: val_loss did not improve from 0.11299\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.9713 - loss: 0.0847 - val_accuracy: 0.9598 - val_loss: 0.1617 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 50...\n",
      "Epoch 50/100\n",
      "   Batch 0: Loss = 0.0418, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9688 - loss: 0.0418\n",
      "Epoch 50: val_loss did not improve from 0.11299\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9688 - loss: 0.0418 - val_accuracy: 0.9598 - val_loss: 0.1448 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 51...\n",
      "Epoch 51/100\n",
      "   Batch 0: Loss = 0.0497, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9802 - loss: 0.0762   Batch 10: Loss = 0.0681, Accuracy = 0.9815\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9785 - loss: 0.0786   Batch 20: Loss = 0.0819, Accuracy = 0.9781\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9792 - loss: 0.0779   Batch 30: Loss = 0.0714, Accuracy = 0.9818\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9796 - loss: 0.0764   Batch 40: Loss = 0.0724, Accuracy = 0.9801\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9796 - loss: 0.0762\n",
      "Epoch 51: val_loss improved from 0.11299 to 0.10817, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model5.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.9786 - loss: 0.0759 - val_accuracy: 0.9688 - val_loss: 0.1082 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 52...\n",
      "Epoch 52/100\n",
      "   Batch 0: Loss = 0.0462, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.9844 - loss: 0.0462\n",
      "Epoch 52: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.0462 - val_accuracy: 0.9710 - val_loss: 0.1319 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 53...\n",
      "Epoch 53/100\n",
      "   Batch 0: Loss = 0.0681, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.9719 - loss: 0.1403   Batch 10: Loss = 0.0997, Accuracy = 0.9787\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9747 - loss: 0.1155   Batch 20: Loss = 0.0811, Accuracy = 0.9784\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9754 - loss: 0.1040   Batch 30: Loss = 0.0837, Accuracy = 0.9750\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9753 - loss: 0.0996   Batch 40: Loss = 0.0843, Accuracy = 0.9758\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9753 - loss: 0.0982\n",
      "Epoch 53: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9749 - loss: 0.0846 - val_accuracy: 0.9643 - val_loss: 0.1431 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 54...\n",
      "Epoch 54/100\n",
      "   Batch 0: Loss = 0.0372, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0372\n",
      "Epoch 54: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0372 - val_accuracy: 0.9509 - val_loss: 0.1635 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 55...\n",
      "Epoch 55/100\n",
      "   Batch 0: Loss = 0.1522, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.9576 - loss: 0.1320   Batch 10: Loss = 0.0842, Accuracy = 0.9730\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.9658 - loss: 0.1082   Batch 20: Loss = 0.1002, Accuracy = 0.9702\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - accuracy: 0.9674 - loss: 0.1045   Batch 30: Loss = 0.0969, Accuracy = 0.9703\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - accuracy: 0.9680 - loss: 0.1023   Batch 40: Loss = 0.0915, Accuracy = 0.9710\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9683 - loss: 0.1013\n",
      "Epoch 55: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.9717 - loss: 0.0910 - val_accuracy: 0.9621 - val_loss: 0.1349 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 56...\n",
      "Epoch 56/100\n",
      "   Batch 0: Loss = 0.0235, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0235\n",
      "Epoch 56: val_loss did not improve from 0.10817\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0235 - val_accuracy: 0.9621 - val_loss: 0.1345 - learning_rate: 1.0000e-08\n",
      "\n",
      "ğŸš€ Starting Epoch 57...\n",
      "Epoch 57/100\n",
      "   Batch 0: Loss = 0.0528, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9776 - loss: 0.0735   Batch 10: Loss = 0.1084, Accuracy = 0.9716\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9760 - loss: 0.0850   Batch 20: Loss = 0.0901, Accuracy = 0.9754\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9757 - loss: 0.0856   Batch 30: Loss = 0.0812, Accuracy = 0.9761\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9758 - loss: 0.0845   Batch 40: Loss = 0.0806, Accuracy = 0.9766\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9759 - loss: 0.0840\n",
      "Epoch 57: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.9768 - loss: 0.0773 - val_accuracy: 0.9643 - val_loss: 0.1470 - learning_rate: 1.0000e-09\n",
      "\n",
      "ğŸš€ Starting Epoch 58...\n",
      "Epoch 58/100\n",
      "   Batch 0: Loss = 0.0611, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.9688 - loss: 0.0611\n",
      "Epoch 58: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0611 - val_accuracy: 0.9643 - val_loss: 0.1520 - learning_rate: 1.0000e-09\n",
      "\n",
      "ğŸš€ Starting Epoch 59...\n",
      "Epoch 59/100\n",
      "   Batch 0: Loss = 0.2205, Accuracy = 0.8906\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.9515 - loss: 0.1101   Batch 10: Loss = 0.0851, Accuracy = 0.9672\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.9608 - loss: 0.0942   Batch 20: Loss = 0.0728, Accuracy = 0.9735\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 259ms/step - accuracy: 0.9655 - loss: 0.0870   Batch 30: Loss = 0.0695, Accuracy = 0.9766\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.9684 - loss: 0.0829   Batch 40: Loss = 0.0697, Accuracy = 0.9793\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9694 - loss: 0.0817\n",
      "Epoch 59: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9786 - loss: 0.0720 - val_accuracy: 0.9576 - val_loss: 0.1492 - learning_rate: 1.0000e-09\n",
      "\n",
      "ğŸš€ Starting Epoch 60...\n",
      "Epoch 60/100\n",
      "   Batch 0: Loss = 0.2160, Accuracy = 0.9219\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.9219 - loss: 0.2160\n",
      "Epoch 60: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9219 - loss: 0.2160 - val_accuracy: 0.9621 - val_loss: 0.1459 - learning_rate: 1.0000e-09\n",
      "\n",
      "ğŸš€ Starting Epoch 61...\n",
      "Epoch 61/100\n",
      "   Batch 0: Loss = 0.1307, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9720 - loss: 0.0759   Batch 10: Loss = 0.0687, Accuracy = 0.9773\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9741 - loss: 0.0729   Batch 20: Loss = 0.0740, Accuracy = 0.9747\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.9743 - loss: 0.0741   Batch 30: Loss = 0.0852, Accuracy = 0.9728\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9740 - loss: 0.0763   Batch 40: Loss = 0.0784, Accuracy = 0.9745\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9740 - loss: 0.0765\n",
      "Epoch 61: val_loss did not improve from 0.10817\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 286ms/step - accuracy: 0.9734 - loss: 0.0804 - val_accuracy: 0.9643 - val_loss: 0.1423 - learning_rate: 1.0000e-09\n",
      "\n",
      "ğŸš€ Starting Epoch 62...\n",
      "Epoch 62/100\n",
      "   Batch 0: Loss = 4.8015, Accuracy = 0.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 4.8015\n",
      "Epoch 62: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0000e+00 - loss: 4.8015 - val_accuracy: 0.9710 - val_loss: 0.1330 - learning_rate: 1.0000e-10\n",
      "\n",
      "ğŸš€ Starting Epoch 63...\n",
      "Epoch 63/100\n",
      "   Batch 0: Loss = 0.1355, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.9860 - loss: 0.0691   Batch 10: Loss = 0.0683, Accuracy = 0.9797\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9804 - loss: 0.0726   Batch 20: Loss = 0.0738, Accuracy = 0.9742\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - accuracy: 0.9773 - loss: 0.0750   Batch 30: Loss = 0.0802, Accuracy = 0.9698\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.9753 - loss: 0.0768   Batch 40: Loss = 0.0800, Accuracy = 0.9703\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9749 - loss: 0.0770\n",
      "Epoch 63: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9709 - loss: 0.0778 - val_accuracy: 0.9710 - val_loss: 0.1673 - learning_rate: 1.0000e-10\n",
      "\n",
      "ğŸš€ Starting Epoch 64...\n",
      "Epoch 64/100\n",
      "   Batch 0: Loss = 0.1657, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.9531 - loss: 0.1657\n",
      "Epoch 64: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1657 - val_accuracy: 0.9643 - val_loss: 0.1352 - learning_rate: 1.0000e-10\n",
      "\n",
      "ğŸš€ Starting Epoch 65...\n",
      "Epoch 65/100\n",
      "   Batch 0: Loss = 0.1130, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9676 - loss: 0.0918   Batch 10: Loss = 0.0907, Accuracy = 0.9702\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9691 - loss: 0.0911   Batch 20: Loss = 0.0889, Accuracy = 0.9725\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9707 - loss: 0.0887   Batch 30: Loss = 0.0792, Accuracy = 0.9755\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9719 - loss: 0.0864   Batch 40: Loss = 0.0785, Accuracy = 0.9758\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9723 - loss: 0.0855\n",
      "Epoch 65: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 280ms/step - accuracy: 0.9764 - loss: 0.0763 - val_accuracy: 0.9665 - val_loss: 0.1303 - learning_rate: 1.0000e-10\n",
      "\n",
      "ğŸš€ Starting Epoch 66...\n",
      "Epoch 66/100\n",
      "   Batch 0: Loss = 0.1030, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9375 - loss: 0.1030\n",
      "Epoch 66: val_loss did not improve from 0.10817\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1030 - val_accuracy: 0.9688 - val_loss: 0.1163 - learning_rate: 1.0000e-10\n",
      "\n",
      "ğŸš€ Starting Epoch 67...\n",
      "Epoch 67/100\n",
      "   Batch 0: Loss = 0.0729, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9743 - loss: 0.0685   Batch 10: Loss = 0.0608, Accuracy = 0.9750\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - accuracy: 0.9755 - loss: 0.0660   Batch 20: Loss = 0.0643, Accuracy = 0.9789\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9763 - loss: 0.0653   Batch 30: Loss = 0.0682, Accuracy = 0.9761\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.9760 - loss: 0.0664   Batch 40: Loss = 0.0726, Accuracy = 0.9738\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9759 - loss: 0.0669\n",
      "Epoch 67: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9749 - loss: 0.0709 - val_accuracy: 0.9643 - val_loss: 0.1479 - learning_rate: 1.0000e-11\n",
      "\n",
      "ğŸš€ Starting Epoch 68...\n",
      "Epoch 68/100\n",
      "   Batch 0: Loss = 0.1069, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9688 - loss: 0.1069\n",
      "Epoch 68: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9688 - loss: 0.1069 - val_accuracy: 0.9665 - val_loss: 0.1458 - learning_rate: 1.0000e-11\n",
      "\n",
      "ğŸš€ Starting Epoch 69...\n",
      "Epoch 69/100\n",
      "   Batch 0: Loss = 0.0231, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9784 - loss: 0.0659   Batch 10: Loss = 0.0638, Accuracy = 0.9759\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9776 - loss: 0.0667   Batch 20: Loss = 0.0766, Accuracy = 0.9740\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9764 - loss: 0.0699   Batch 30: Loss = 0.0784, Accuracy = 0.9729\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9755 - loss: 0.0726   Batch 40: Loss = 0.0823, Accuracy = 0.9731\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9753 - loss: 0.0735\n",
      "Epoch 69: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 281ms/step - accuracy: 0.9735 - loss: 0.0825 - val_accuracy: 0.9688 - val_loss: 0.1529 - learning_rate: 1.0000e-11\n",
      "\n",
      "ğŸš€ Starting Epoch 70...\n",
      "Epoch 70/100\n",
      "   Batch 0: Loss = 0.0730, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9531 - loss: 0.0730\n",
      "Epoch 70: val_loss did not improve from 0.10817\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9531 - loss: 0.0730 - val_accuracy: 0.9621 - val_loss: 0.1480 - learning_rate: 1.0000e-11\n",
      "\n",
      "ğŸš€ Starting Epoch 71...\n",
      "Epoch 71/100\n",
      "   Batch 0: Loss = 0.2066, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.9521 - loss: 0.1631   Batch 10: Loss = 0.1197, Accuracy = 0.9641\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - accuracy: 0.9605 - loss: 0.1338   Batch 20: Loss = 0.0939, Accuracy = 0.9727\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.9641 - loss: 0.1214   Batch 30: Loss = 0.0917, Accuracy = 0.9719\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9662 - loss: 0.1135   Batch 40: Loss = 0.0846, Accuracy = 0.9742\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9670 - loss: 0.1107\n",
      "Epoch 71: val_loss did not improve from 0.10817\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9746 - loss: 0.0824 - val_accuracy: 0.9643 - val_loss: 0.1476 - learning_rate: 1.0000e-11\n",
      "Epoch 71: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(str(MODELS_DIR / \"classifier-resnet-model4.keras\"))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model5.keras\"), verbose=1,save_best_only=True)\n",
    "\n",
    "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-12),\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping,lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "G1uXBduYEP59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765234164.949326    4896 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.0180, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 371ms/step - accuracy: 0.9537 - loss: 0.1464   Batch 10: Loss = 0.1955, Accuracy = 0.9418\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - accuracy: 0.9460 - loss: 0.1693   Batch 20: Loss = 0.1864, Accuracy = 0.9405\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m10s\u001b[0m 718ms/step - accuracy: 0.9449 - loss: 0.1711   Batch 30: Loss = 0.1677, Accuracy = 0.9438\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m2s\u001b[0m 628ms/step - accuracy: 0.9452 - loss: 0.1692   Batch 40: Loss = 0.1591, Accuracy = 0.9477\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.9454 - loss: 0.1682\n",
      "Epoch 1: val_loss improved from None to 0.57928, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model6.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 723ms/step - accuracy: 0.9470 - loss: 0.1585 - val_accuracy: 0.9263 - val_loss: 0.5793 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 2...\n",
      "Epoch 2/100\n",
      "   Batch 0: Loss = 0.1312, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.9531 - loss: 0.1312\n",
      "Epoch 2: val_loss did not improve from 0.57928\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1312 - val_accuracy: 0.9241 - val_loss: 0.6162 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 3...\n",
      "Epoch 3/100\n",
      "   Batch 0: Loss = 0.1326, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10s\u001b[0m 320ms/step - accuracy: 0.9379 - loss: 0.1549   Batch 10: Loss = 0.1275, Accuracy = 0.9531\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 284ms/step - accuracy: 0.9457 - loss: 0.1431   Batch 20: Loss = 0.1303, Accuracy = 0.9546\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.9493 - loss: 0.1366   Batch 30: Loss = 0.1259, Accuracy = 0.9578\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.9511 - loss: 0.1355   Batch 40: Loss = 0.1371, Accuracy = 0.9551\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9515 - loss: 0.1357\n",
      "Epoch 3: val_loss did not improve from 0.57928\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - accuracy: 0.9557 - loss: 0.1360 - val_accuracy: 0.9330 - val_loss: 2.2949 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 4...\n",
      "Epoch 4/100\n",
      "   Batch 0: Loss = 0.0786, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.9688 - loss: 0.0786\n",
      "Epoch 4: val_loss did not improve from 0.57928\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0786 - val_accuracy: 0.9241 - val_loss: 1.6349 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 5...\n",
      "Epoch 5/100\n",
      "   Batch 0: Loss = 0.0978, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9507 - loss: 0.1212   Batch 10: Loss = 0.1168, Accuracy = 0.9503\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - accuracy: 0.9521 - loss: 0.1173   Batch 20: Loss = 0.1181, Accuracy = 0.9571\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 0.9529 - loss: 0.1227   Batch 30: Loss = 0.1370, Accuracy = 0.9552\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9529 - loss: 0.1290   Batch 40: Loss = 0.1568, Accuracy = 0.9512\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9528 - loss: 0.1313\n",
      "Epoch 5: val_loss did not improve from 0.57928\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.9517 - loss: 0.1532 - val_accuracy: 0.7545 - val_loss: 1.2160 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 6...\n",
      "Epoch 6/100\n",
      "   Batch 0: Loss = 0.1290, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.9531 - loss: 0.1290\n",
      "Epoch 6: val_loss did not improve from 0.57928\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1290 - val_accuracy: 0.7455 - val_loss: 1.4135 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 7...\n",
      "Epoch 7/100\n",
      "   Batch 0: Loss = 0.2076, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9347 - loss: 0.1740   Batch 10: Loss = 0.1553, Accuracy = 0.9446\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.9398 - loss: 0.1622   Batch 20: Loss = 0.1508, Accuracy = 0.9438\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.9424 - loss: 0.1561   Batch 30: Loss = 0.1346, Accuracy = 0.9521\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.9450 - loss: 0.1497   Batch 40: Loss = 0.1261, Accuracy = 0.9539\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9459 - loss: 0.1474\n",
      "Epoch 7: val_loss improved from 0.57928 to 0.18897, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model6.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 323ms/step - accuracy: 0.9553 - loss: 0.1228 - val_accuracy: 0.9554 - val_loss: 0.1890 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 8...\n",
      "Epoch 8/100\n",
      "   Batch 0: Loss = 0.1375, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.9531 - loss: 0.1375\n",
      "Epoch 8: val_loss did not improve from 0.18897\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9531 - loss: 0.1375 - val_accuracy: 0.9464 - val_loss: 0.1894 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 9...\n",
      "Epoch 9/100\n",
      "   Batch 0: Loss = 0.0490, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9785 - loss: 0.0850   Batch 10: Loss = 0.0830, Accuracy = 0.9744\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 242ms/step - accuracy: 0.9758 - loss: 0.0851   Batch 20: Loss = 0.0869, Accuracy = 0.9725\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - accuracy: 0.9749 - loss: 0.0864   Batch 30: Loss = 0.0875, Accuracy = 0.9743\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9741 - loss: 0.0881   Batch 40: Loss = 0.0963, Accuracy = 0.9703\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9738 - loss: 0.0888\n",
      "Epoch 9: val_loss improved from 0.18897 to 0.15187, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model6.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 298ms/step - accuracy: 0.9702 - loss: 0.0961 - val_accuracy: 0.9621 - val_loss: 0.1519 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 10...\n",
      "Epoch 10/100\n",
      "   Batch 0: Loss = 0.0746, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - accuracy: 0.9844 - loss: 0.0746\n",
      "Epoch 10: val_loss improved from 0.15187 to 0.12975, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model6.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9844 - loss: 0.0746 - val_accuracy: 0.9643 - val_loss: 0.1298 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 11...\n",
      "Epoch 11/100\n",
      "   Batch 0: Loss = 0.0874, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.9740 - loss: 0.0756   Batch 10: Loss = 0.0778, Accuracy = 0.9750\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.9738 - loss: 0.0765   Batch 20: Loss = 0.0787, Accuracy = 0.9735\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - accuracy: 0.9736 - loss: 0.0772   Batch 30: Loss = 0.0780, Accuracy = 0.9729\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.9736 - loss: 0.0771   Batch 40: Loss = 0.0784, Accuracy = 0.9738\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9736 - loss: 0.0774\n",
      "Epoch 11: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9728 - loss: 0.0822 - val_accuracy: 0.9643 - val_loss: 0.1465 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 12...\n",
      "Epoch 12/100\n",
      "   Batch 0: Loss = 0.0812, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9844 - loss: 0.0812\n",
      "Epoch 12: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.0812 - val_accuracy: 0.9531 - val_loss: 0.1353 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 13...\n",
      "Epoch 13/100\n",
      "   Batch 0: Loss = 0.0529, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9724 - loss: 0.0807   Batch 10: Loss = 0.0805, Accuracy = 0.9787\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9754 - loss: 0.0785   Batch 20: Loss = 0.0767, Accuracy = 0.9781\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9760 - loss: 0.0786   Batch 30: Loss = 0.0847, Accuracy = 0.9750\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9755 - loss: 0.0804   Batch 40: Loss = 0.0908, Accuracy = 0.9731\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9754 - loss: 0.0811\n",
      "Epoch 13: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.9749 - loss: 0.0864 - val_accuracy: 0.9643 - val_loss: 0.1307 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 14...\n",
      "Epoch 14/100\n",
      "   Batch 0: Loss = 0.1169, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.9375 - loss: 0.1169\n",
      "Epoch 14: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1169 - val_accuracy: 0.9665 - val_loss: 0.1498 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 15...\n",
      "Epoch 15/100\n",
      "   Batch 0: Loss = 0.0272, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9777 - loss: 0.0639   Batch 10: Loss = 0.0732, Accuracy = 0.9716\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9759 - loss: 0.0676   Batch 20: Loss = 0.0791, Accuracy = 0.9717\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9749 - loss: 0.0711   Batch 30: Loss = 0.0812, Accuracy = 0.9723\n",
      "\u001b[1m39/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.9746 - loss: 0.0727   Batch 40: Loss = 0.0730, Accuracy = 0.9754\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9746 - loss: 0.0731\n",
      "Epoch 15: val_loss did not improve from 0.12975\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9742 - loss: 0.0777 - val_accuracy: 0.9531 - val_loss: 0.1836 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 16...\n",
      "Epoch 16/100\n",
      "   Batch 0: Loss = 0.0704, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9844 - loss: 0.0704\n",
      "Epoch 16: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.0704 - val_accuracy: 0.9509 - val_loss: 0.1393 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 17...\n",
      "Epoch 17/100\n",
      "   Batch 0: Loss = 0.1575, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9672 - loss: 0.1005   Batch 10: Loss = 0.0746, Accuracy = 0.9744\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.9710 - loss: 0.0860   Batch 20: Loss = 0.0665, Accuracy = 0.9766\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9721 - loss: 0.0818   Batch 30: Loss = 0.0782, Accuracy = 0.9745\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9730 - loss: 0.0802   Batch 40: Loss = 0.0729, Accuracy = 0.9770\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9733 - loss: 0.0796\n",
      "Epoch 17: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.9768 - loss: 0.0744 - val_accuracy: 0.9598 - val_loss: 0.1473 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 18...\n",
      "Epoch 18/100\n",
      "   Batch 0: Loss = 0.0470, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - accuracy: 0.9844 - loss: 0.0470\n",
      "Epoch 18: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0470 - val_accuracy: 0.9509 - val_loss: 0.1862 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 19...\n",
      "Epoch 19/100\n",
      "   Batch 0: Loss = 0.0317, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9866 - loss: 0.0616   Batch 10: Loss = 0.0820, Accuracy = 0.9735\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - accuracy: 0.9802 - loss: 0.0703   Batch 20: Loss = 0.0708, Accuracy = 0.9781\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9789 - loss: 0.0714   Batch 30: Loss = 0.0739, Accuracy = 0.9755\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9783 - loss: 0.0716   Batch 40: Loss = 0.0745, Accuracy = 0.9766\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9780 - loss: 0.0720\n",
      "Epoch 19: val_loss did not improve from 0.12975\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 298ms/step - accuracy: 0.9753 - loss: 0.0761 - val_accuracy: 0.9643 - val_loss: 0.1373 - learning_rate: 1.0000e-05\n",
      "\n",
      "ğŸš€ Starting Epoch 20...\n",
      "Epoch 20/100\n",
      "   Batch 0: Loss = 0.0306, Accuracy = 1.0000\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0306\n",
      "Epoch 20: val_loss did not improve from 0.12975\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.9621 - val_loss: 0.1335 - learning_rate: 1.0000e-05\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(str(MODELS_DIR / \"classifier-resnet-model5.keras\"))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model6.keras\"), verbose=1,save_best_only=True)\n",
    "\n",
    "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-12),\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping,lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7FSop117b69",
    "outputId": "5c27d2da-51a8-4d0b-9999-a7acdc13a162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765234432.379322    4897 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.0602, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9564 - loss: 0.1692   Batch 10: Loss = 0.2043, Accuracy = 0.9446\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 242ms/step - accuracy: 0.9520 - loss: 0.1780   Batch 20: Loss = 0.1731, Accuracy = 0.9472\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - accuracy: 0.9491 - loss: 0.1799   Batch 30: Loss = 0.1748, Accuracy = 0.9451\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9483 - loss: 0.1796   Batch 40: Loss = 0.1749, Accuracy = 0.9470\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.9483 - loss: 0.1790\n",
      "Epoch 1: val_loss improved from None to 1.04625, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 573ms/step - accuracy: 0.9473 - loss: 0.1745 - val_accuracy: 0.8728 - val_loss: 1.0463 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 2...\n",
      "Epoch 2/100\n",
      "   Batch 0: Loss = 0.1547, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.9688 - loss: 0.1547\n",
      "Epoch 2: val_loss improved from 1.04625 to 1.00290, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9688 - loss: 0.1547 - val_accuracy: 0.8839 - val_loss: 1.0029 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 3...\n",
      "Epoch 3/100\n",
      "   Batch 0: Loss = 0.0793, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 247ms/step - accuracy: 0.9600 - loss: 0.1170   Batch 10: Loss = 0.1258, Accuracy = 0.9616\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 270ms/step - accuracy: 0.9610 - loss: 0.1216   Batch 20: Loss = 0.1205, Accuracy = 0.9633\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.9613 - loss: 0.1215   Batch 30: Loss = 0.1213, Accuracy = 0.9615\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.9615 - loss: 0.1215   Batch 40: Loss = 0.1262, Accuracy = 0.9613\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9614 - loss: 0.1222\n",
      "Epoch 3: val_loss did not improve from 1.00290\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9600 - loss: 0.1302 - val_accuracy: 0.8683 - val_loss: 1.1652 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 4...\n",
      "Epoch 4/100\n",
      "   Batch 0: Loss = 0.0857, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.9844 - loss: 0.0857\n",
      "Epoch 4: val_loss did not improve from 1.00290\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.0857 - val_accuracy: 0.8661 - val_loss: 1.1411 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 5...\n",
      "Epoch 5/100\n",
      "   Batch 0: Loss = 0.1073, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9525 - loss: 0.1298   Batch 10: Loss = 0.1297, Accuracy = 0.9517\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - accuracy: 0.9511 - loss: 0.1312   Batch 20: Loss = 0.1396, Accuracy = 0.9485\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - accuracy: 0.9482 - loss: 0.1478   Batch 30: Loss = 0.1952, Accuracy = 0.9360\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9442 - loss: 0.1603   Batch 40: Loss = 0.1974, Accuracy = 0.9301\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9429 - loss: 0.1636\n",
      "Epoch 5: val_loss improved from 1.00290 to 0.91493, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.9303 - loss: 0.1953 - val_accuracy: 0.8036 - val_loss: 0.9149 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 6...\n",
      "Epoch 6/100\n",
      "   Batch 0: Loss = 0.0970, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.9688 - loss: 0.0970\n",
      "Epoch 6: val_loss did not improve from 0.91493\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9688 - loss: 0.0970 - val_accuracy: 0.8036 - val_loss: 0.9505 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 7...\n",
      "Epoch 7/100\n",
      "   Batch 0: Loss = 0.0692, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.9683 - loss: 0.1296   Batch 10: Loss = 0.1821, Accuracy = 0.9485\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.9524 - loss: 0.1785   Batch 20: Loss = 0.2353, Accuracy = 0.9321\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.9446 - loss: 0.1972   Batch 30: Loss = 0.2254, Accuracy = 0.9318\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.9411 - loss: 0.2039   Batch 40: Loss = 0.2236, Accuracy = 0.9305\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9402 - loss: 0.2053\n",
      "Epoch 7: val_loss did not improve from 0.91493\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - accuracy: 0.9321 - loss: 0.2158 - val_accuracy: 0.6384 - val_loss: 2.0886 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 8...\n",
      "Epoch 8/100\n",
      "   Batch 0: Loss = 0.1813, Accuracy = 0.9375\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9375 - loss: 0.1813\n",
      "Epoch 8: val_loss did not improve from 0.91493\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9375 - loss: 0.1813 - val_accuracy: 0.6183 - val_loss: 2.3972 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 9...\n",
      "Epoch 9/100\n",
      "   Batch 0: Loss = 0.1449, Accuracy = 0.9219\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9300 - loss: 0.1534   Batch 10: Loss = 0.1600, Accuracy = 0.9332\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 242ms/step - accuracy: 0.9302 - loss: 0.1596   Batch 20: Loss = 0.1703, Accuracy = 0.9301\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - accuracy: 0.9318 - loss: 0.1602   Batch 30: Loss = 0.1574, Accuracy = 0.9395\n",
      "\u001b[1m39/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 0.9345 - loss: 0.1580   Batch 40: Loss = 0.1468, Accuracy = 0.9465\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9359 - loss: 0.1565\n",
      "Epoch 9: val_loss improved from 0.91493 to 0.61363, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.9481 - loss: 0.1430 - val_accuracy: 0.9353 - val_loss: 0.6136 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 10...\n",
      "Epoch 10/100\n",
      "   Batch 0: Loss = 0.0748, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 187ms/step - accuracy: 0.9531 - loss: 0.0748\n",
      "Epoch 10: val_loss did not improve from 0.61363\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.0748 - val_accuracy: 0.9286 - val_loss: 0.7125 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 11...\n",
      "Epoch 11/100\n",
      "   Batch 0: Loss = 0.1820, Accuracy = 0.9219\n",
      "\u001b[1m 9/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.9499 - loss: 0.1951   Batch 10: Loss = 0.2553, Accuracy = 0.9392\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9411 - loss: 0.2251   Batch 20: Loss = 0.2798, Accuracy = 0.9188\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - accuracy: 0.9324 - loss: 0.2406   Batch 30: Loss = 0.2557, Accuracy = 0.9178\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.9292 - loss: 0.2413   Batch 40: Loss = 0.2331, Accuracy = 0.9207\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9286 - loss: 0.2401\n",
      "Epoch 11: val_loss did not improve from 0.61363\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.9252 - loss: 0.2232 - val_accuracy: 0.8571 - val_loss: 1.9179 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 12...\n",
      "Epoch 12/100\n",
      "   Batch 0: Loss = 0.1117, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.9531 - loss: 0.1117\n",
      "Epoch 12: val_loss did not improve from 0.61363\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1117 - val_accuracy: 0.8616 - val_loss: 2.2801 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 13...\n",
      "Epoch 13/100\n",
      "   Batch 0: Loss = 0.1260, Accuracy = 0.8906\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9455 - loss: 0.1235   Batch 10: Loss = 0.1284, Accuracy = 0.9545\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - accuracy: 0.9498 - loss: 0.1260   Batch 20: Loss = 0.1377, Accuracy = 0.9532\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.9510 - loss: 0.1296   Batch 30: Loss = 0.1386, Accuracy = 0.9542\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9516 - loss: 0.1320   Batch 40: Loss = 0.1398, Accuracy = 0.9539\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9518 - loss: 0.1327\n",
      "Epoch 13: val_loss did not improve from 0.61363\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 281ms/step - accuracy: 0.9535 - loss: 0.1405 - val_accuracy: 0.8817 - val_loss: 1.1754 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 14...\n",
      "Epoch 14/100\n",
      "   Batch 0: Loss = 0.0838, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9688 - loss: 0.0838\n",
      "Epoch 14: val_loss did not improve from 0.61363\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9688 - loss: 0.0838 - val_accuracy: 0.8884 - val_loss: 1.5120 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 15...\n",
      "Epoch 15/100\n",
      "   Batch 0: Loss = 0.1201, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9628 - loss: 0.1197   Batch 10: Loss = 0.1185, Accuracy = 0.9616\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - accuracy: 0.9604 - loss: 0.1176   Batch 20: Loss = 0.1180, Accuracy = 0.9571\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9599 - loss: 0.1159   Batch 30: Loss = 0.1072, Accuracy = 0.9610\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9604 - loss: 0.1130   Batch 40: Loss = 0.1001, Accuracy = 0.9633\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9606 - loss: 0.1118\n",
      "Epoch 15: val_loss improved from 0.61363 to 0.50693, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 318ms/step - accuracy: 0.9629 - loss: 0.1005 - val_accuracy: 0.9397 - val_loss: 0.5069 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 16...\n",
      "Epoch 16/100\n",
      "   Batch 0: Loss = 0.0543, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9844 - loss: 0.0543\n",
      "Epoch 16: val_loss improved from 0.50693 to 0.47752, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9844 - loss: 0.0543 - val_accuracy: 0.9442 - val_loss: 0.4775 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 17...\n",
      "Epoch 17/100\n",
      "   Batch 0: Loss = 0.0787, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9660 - loss: 0.0862   Batch 10: Loss = 0.0882, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9658 - loss: 0.0875   Batch 20: Loss = 0.0923, Accuracy = 0.9658\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9657 - loss: 0.0890   Batch 30: Loss = 0.0964, Accuracy = 0.9651\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9655 - loss: 0.0915   Batch 40: Loss = 0.0994, Accuracy = 0.9641\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9654 - loss: 0.0923\n",
      "Epoch 17: val_loss improved from 0.47752 to 0.17108, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.9644 - loss: 0.1003 - val_accuracy: 0.9554 - val_loss: 0.1711 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 18...\n",
      "Epoch 18/100\n",
      "   Batch 0: Loss = 0.1617, Accuracy = 0.9688\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.9688 - loss: 0.1617\n",
      "Epoch 18: val_loss did not improve from 0.17108\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.1617 - val_accuracy: 0.9621 - val_loss: 0.1814 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 19...\n",
      "Epoch 19/100\n",
      "   Batch 0: Loss = 0.1007, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9792 - loss: 0.0921   Batch 10: Loss = 0.0883, Accuracy = 0.9744\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9744 - loss: 0.0918   Batch 20: Loss = 0.0934, Accuracy = 0.9680\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9722 - loss: 0.0933   Batch 30: Loss = 0.0948, Accuracy = 0.9688\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9713 - loss: 0.0938   Batch 40: Loss = 0.0971, Accuracy = 0.9684\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9710 - loss: 0.0942\n",
      "Epoch 19: val_loss improved from 0.17108 to 0.16020, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 317ms/step - accuracy: 0.9684 - loss: 0.0991 - val_accuracy: 0.9531 - val_loss: 0.1602 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 20...\n",
      "Epoch 20/100\n",
      "   Batch 0: Loss = 0.0285, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.9844 - loss: 0.0285\n",
      "Epoch 20: val_loss improved from 0.16020 to 0.14016, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model7.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9844 - loss: 0.0285 - val_accuracy: 0.9665 - val_loss: 0.1402 - learning_rate: 1.0000e-04\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "model=load_model(str(MODELS_DIR / \"classifier-resnet-model6.keras\"))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model7.keras\"), verbose=1,save_best_only=True)\n",
    "\n",
    "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-12),\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping,lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgSQxqP2Mx8g",
    "outputId": "747aff92-c5d0-4212-9aa7-2f8164db2a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Epoch 1...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765234664.836885    4896 subprocess_compilation.cc:348] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_15', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0: Loss = 0.1729, Accuracy = 0.9375\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.9599 - loss: 0.1270   Batch 10: Loss = 0.1892, Accuracy = 0.9517\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.9519 - loss: 0.1618   Batch 20: Loss = 0.1971, Accuracy = 0.9382\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - accuracy: 0.9472 - loss: 0.1733   Batch 30: Loss = 0.1941, Accuracy = 0.9360\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 491ms/step - accuracy: 0.9450 - loss: 0.1775   Batch 40: Loss = 0.1867, Accuracy = 0.9399\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.9447 - loss: 0.1778\n",
      "Epoch 1: val_loss improved from None to 0.43370, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 624ms/step - accuracy: 0.9433 - loss: 0.1768 - val_accuracy: 0.9196 - val_loss: 0.4337 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 2...\n",
      "Epoch 2/100\n",
      "   Batch 0: Loss = 0.1647, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.9531 - loss: 0.1647\n",
      "Epoch 2: val_loss did not improve from 0.43370\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9531 - loss: 0.1647 - val_accuracy: 0.8750 - val_loss: 0.6062 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 3...\n",
      "Epoch 3/100\n",
      "   Batch 0: Loss = 0.1226, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.9361 - loss: 0.2780   Batch 10: Loss = 0.3196, Accuracy = 0.9017\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - accuracy: 0.9240 - loss: 0.2811   Batch 20: Loss = 0.2547, Accuracy = 0.9188\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9238 - loss: 0.2667   Batch 30: Loss = 0.2210, Accuracy = 0.9266\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9251 - loss: 0.2529   Batch 40: Loss = 0.2052, Accuracy = 0.9297\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9256 - loss: 0.2487\n",
      "Epoch 3: val_loss improved from 0.43370 to 0.35389, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.9317 - loss: 0.2060 - val_accuracy: 0.8973 - val_loss: 0.3539 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 4...\n",
      "Epoch 4/100\n",
      "   Batch 0: Loss = 0.1851, Accuracy = 0.9219\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - accuracy: 0.9219 - loss: 0.1851\n",
      "Epoch 4: val_loss improved from 0.35389 to 0.34484, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9219 - loss: 0.1851 - val_accuracy: 0.9129 - val_loss: 0.3448 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 5...\n",
      "Epoch 5/100\n",
      "   Batch 0: Loss = 0.1046, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9486 - loss: 0.1529   Batch 10: Loss = 0.1536, Accuracy = 0.9460\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9475 - loss: 0.1571   Batch 20: Loss = 0.1515, Accuracy = 0.9509\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.9491 - loss: 0.1535   Batch 30: Loss = 0.1382, Accuracy = 0.9556\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9512 - loss: 0.1476   Batch 40: Loss = 0.1320, Accuracy = 0.9567\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9516 - loss: 0.1466\n",
      "Epoch 5: val_loss did not improve from 0.34484\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9553 - loss: 0.1394 - val_accuracy: 0.8438 - val_loss: 0.6335 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 6...\n",
      "Epoch 6/100\n",
      "   Batch 0: Loss = 0.0941, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9531 - loss: 0.0941\n",
      "Epoch 6: val_loss did not improve from 0.34484\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9531 - loss: 0.0941 - val_accuracy: 0.8504 - val_loss: 0.5274 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 7...\n",
      "Epoch 7/100\n",
      "   Batch 0: Loss = 0.1434, Accuracy = 0.9531\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9513 - loss: 0.1369   Batch 10: Loss = 0.1284, Accuracy = 0.9588\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9558 - loss: 0.1306   Batch 20: Loss = 0.1186, Accuracy = 0.9613\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.9570 - loss: 0.1284   Batch 30: Loss = 0.1326, Accuracy = 0.9563\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9552 - loss: 0.1322   Batch 40: Loss = 0.1530, Accuracy = 0.9442\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9540 - loss: 0.1343\n",
      "Epoch 7: val_loss did not improve from 0.34484\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.9419 - loss: 0.1576 - val_accuracy: 0.8549 - val_loss: 0.4390 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 8...\n",
      "Epoch 8/100\n",
      "   Batch 0: Loss = 0.2722, Accuracy = 0.8750\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.8750 - loss: 0.2722\n",
      "Epoch 8: val_loss did not improve from 0.34484\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8750 - loss: 0.2722 - val_accuracy: 0.8616 - val_loss: 0.4679 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 9...\n",
      "Epoch 9/100\n",
      "   Batch 0: Loss = 0.1353, Accuracy = 0.9688\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9558 - loss: 0.1304   Batch 10: Loss = 0.1190, Accuracy = 0.9574\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9565 - loss: 0.1348   Batch 20: Loss = 0.1519, Accuracy = 0.9554\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.9550 - loss: 0.1402   Batch 30: Loss = 0.1463, Accuracy = 0.9536\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9551 - loss: 0.1405   Batch 40: Loss = 0.1357, Accuracy = 0.9570\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9553 - loss: 0.1401\n",
      "Epoch 9: val_loss improved from 0.34484 to 0.18857, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 304ms/step - accuracy: 0.9568 - loss: 0.1361 - val_accuracy: 0.9554 - val_loss: 0.1886 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 10...\n",
      "Epoch 10/100\n",
      "   Batch 0: Loss = 0.1310, Accuracy = 0.8906\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - accuracy: 0.8906 - loss: 0.1310\n",
      "Epoch 10: val_loss did not improve from 0.18857\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8906 - loss: 0.1310 - val_accuracy: 0.9464 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 11...\n",
      "Epoch 11/100\n",
      "   Batch 0: Loss = 0.0358, Accuracy = 1.0000\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m10s\u001b[0m 308ms/step - accuracy: 0.9750 - loss: 0.0904   Batch 10: Loss = 0.1096, Accuracy = 0.9659\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.9701 - loss: 0.1010   Batch 20: Loss = 0.1048, Accuracy = 0.9665\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.9692 - loss: 0.1019   Batch 30: Loss = 0.1028, Accuracy = 0.9677\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.9686 - loss: 0.1024   Batch 40: Loss = 0.1043, Accuracy = 0.9680\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9686 - loss: 0.1027\n",
      "Epoch 11: val_loss improved from 0.18857 to 0.14988, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 319ms/step - accuracy: 0.9680 - loss: 0.1067 - val_accuracy: 0.9576 - val_loss: 0.1499 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 12...\n",
      "Epoch 12/100\n",
      "   Batch 0: Loss = 0.1294, Accuracy = 0.9531\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.9531 - loss: 0.1294\n",
      "Epoch 12: val_loss did not improve from 0.14988\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1294 - val_accuracy: 0.9554 - val_loss: 0.1742 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 13...\n",
      "Epoch 13/100\n",
      "   Batch 0: Loss = 0.0922, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9616 - loss: 0.0921   Batch 10: Loss = 0.0809, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9661 - loss: 0.0869   Batch 20: Loss = 0.0838, Accuracy = 0.9725\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9682 - loss: 0.0869   Batch 30: Loss = 0.0948, Accuracy = 0.9723\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9692 - loss: 0.0890   Batch 40: Loss = 0.1032, Accuracy = 0.9699\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9692 - loss: 0.0902\n",
      "Epoch 13: val_loss improved from 0.14988 to 0.13892, saving model to /home/fabit/brain-tumor-detection/models/classifier-resnet-model8.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.9699 - loss: 0.1026 - val_accuracy: 0.9621 - val_loss: 0.1389 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 14...\n",
      "Epoch 14/100\n",
      "   Batch 0: Loss = 0.0625, Accuracy = 0.9844\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - accuracy: 0.9844 - loss: 0.0625\n",
      "Epoch 14: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9844 - loss: 0.0625 - val_accuracy: 0.9554 - val_loss: 0.1674 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 15...\n",
      "Epoch 15/100\n",
      "   Batch 0: Loss = 0.0727, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.9796 - loss: 0.0811   Batch 10: Loss = 0.0922, Accuracy = 0.9688\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 260ms/step - accuracy: 0.9743 - loss: 0.0901   Batch 20: Loss = 0.1013, Accuracy = 0.9688\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.9719 - loss: 0.0937   Batch 30: Loss = 0.1040, Accuracy = 0.9651\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.9703 - loss: 0.0959   Batch 40: Loss = 0.1028, Accuracy = 0.9649\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9699 - loss: 0.0963\n",
      "Epoch 15: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 297ms/step - accuracy: 0.9659 - loss: 0.0991 - val_accuracy: 0.9420 - val_loss: 0.1614 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 16...\n",
      "Epoch 16/100\n",
      "   Batch 0: Loss = 0.1397, Accuracy = 0.9219\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9219 - loss: 0.1397\n",
      "Epoch 16: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9219 - loss: 0.1397 - val_accuracy: 0.9643 - val_loss: 0.1557 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 17...\n",
      "Epoch 17/100\n",
      "   Batch 0: Loss = 0.0442, Accuracy = 0.9844\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9714 - loss: 0.0715   Batch 10: Loss = 0.0864, Accuracy = 0.9616\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9685 - loss: 0.0757   Batch 20: Loss = 0.0780, Accuracy = 0.9673\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - accuracy: 0.9680 - loss: 0.0776   Batch 30: Loss = 0.0834, Accuracy = 0.9682\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9664 - loss: 0.0844   Batch 40: Loss = 0.1494, Accuracy = 0.9461\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9641 - loss: 0.0910\n",
      "Epoch 17: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 285ms/step - accuracy: 0.9364 - loss: 0.1647 - val_accuracy: 0.6362 - val_loss: 1.4127 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 18...\n",
      "Epoch 18/100\n",
      "   Batch 0: Loss = 0.6548, Accuracy = 0.7812\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.7812 - loss: 0.6548\n",
      "Epoch 18: val_loss did not improve from 0.13892\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7812 - loss: 0.6548 - val_accuracy: 0.6607 - val_loss: 1.9685 - learning_rate: 0.0010\n",
      "\n",
      "ğŸš€ Starting Epoch 19...\n",
      "Epoch 19/100\n",
      "   Batch 0: Loss = 0.5625, Accuracy = 0.8438\n",
      "\u001b[1m10/44\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.7937 - loss: 0.5089   Batch 10: Loss = 0.4527, Accuracy = 0.8026\n",
      "\u001b[1m20/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.7920 - loss: 0.4847   Batch 20: Loss = 0.4528, Accuracy = 0.7909\n",
      "\u001b[1m30/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.7931 - loss: 0.4748   Batch 30: Loss = 0.4491, Accuracy = 0.8019\n",
      "\u001b[1m40/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7950 - loss: 0.4677   Batch 40: Loss = 0.4386, Accuracy = 0.8056\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.7959 - loss: 0.4653\n",
      "Epoch 19: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 297ms/step - accuracy: 0.8042 - loss: 0.4416 - val_accuracy: 0.7388 - val_loss: 0.6238 - learning_rate: 1.0000e-04\n",
      "\n",
      "ğŸš€ Starting Epoch 20...\n",
      "Epoch 20/100\n",
      "   Batch 0: Loss = 0.3714, Accuracy = 0.8750\n",
      "\u001b[1m 1/44\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.8750 - loss: 0.3714\n",
      "Epoch 20: val_loss did not improve from 0.13892\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8750 - loss: 0.3714 - val_accuracy: 0.7143 - val_loss: 0.6251 - learning_rate: 1.0000e-04\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "model=load_model(str(MODELS_DIR / \"classifier-resnet-model7.keras\"))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=str(MODELS_DIR / \"classifier-resnet-model8.keras\"), verbose=1,save_best_only=True)\n",
    "\n",
    "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-12),\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // BATCH_SIZE, epochs = 100, validation_data= valid_generator, validation_steps= valid_generator.n // BATCH_SIZE, callbacks=[ForceProgressPrint(), checkpointer, earlystopping,lr_reduce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12cadIABJEO-"
   },
   "source": [
    "# TRAINED MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "WjbV7cu0b1Wd"
   },
   "outputs": [],
   "source": [
    "# Load pretrained modeL\n",
    "\n",
    "model=load_model(str(MODELS_DIR / \"classifier-resnet-model8.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aF5lW4D2JHTf",
    "outputId": "8418fb14-d213-4a3a-e91c-22fd7241149e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict(test_generator, steps = test_generator.n // BATCH_SIZE, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "o26IglwYJLA0"
   },
   "outputs": [],
   "source": [
    "# Obtain the predicted class from the model prediction\n",
    "predict = []\n",
    "\n",
    "for i in test_predict:\n",
    "  predict.append(str(np.argmax(i)))\n",
    "\n",
    "predict = np.asarray(predict)\n",
    "predict = predict.astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7EnAy8FJMTi",
    "outputId": "e1f86c43-4deb-4efd-c165-0db5186a68ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we have used test generator, it limited the images to len(predict), due to batch size\n",
    "original = np.asarray(test['mask'])[:len(predict)]\n",
    "len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9722222222222222\n",
      "f1_score:  0.9572192513368984\n",
      "precision_score:  0.9521276595744681\n",
      "recall_score:  0.9623655913978495\n"
     ]
    }
   ],
   "source": [
    "# Obtain the accuracy of the model\n",
    "\n",
    "print(\"accuracy_score: \", accuracy_score(original, predict))\n",
    "print(\"f1_score: \", f1_score(original, predict,pos_label=\"1\"))\n",
    "print(\"precision_score: \", precision_score(original, predict,pos_label=\"1\"))\n",
    "print(\"recall_score: \", recall_score(original, predict,pos_label=\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       390\n",
      "           1       0.95      0.96      0.96       186\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       576\n",
      "   macro avg       0.97      0.97      0.97       576\n",
      "weighted avg       0.97      0.97      0.97       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(original, predict, labels = [0,1])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(original, predict)\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original=original.astype(\"int\")\n",
    "predict=predict.astype(\"int\")\n",
    "RocCurveDisplay.from_predictions(original, predict);\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
