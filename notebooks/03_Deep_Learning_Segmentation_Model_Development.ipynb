{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0oz3ShXF0Qa"
      },
      "source": [
        "# TASK #2: IMPORT LIBRARIES AND DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "BDv169iyF3aL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score,RocCurveDisplay, precision_score, f1_score\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from google.colab import files #library to upload files to colab notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oDTMhZP6QNx",
        "outputId": "a90396c0-3c9e-48e3-dfca-8e579289c8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# You will need to mount your drive using the following commands:\n",
        "# For more information regarding mounting, please check this out: https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6gXD9ntF7Ob",
        "outputId": "631fb9fe-e317-48a2-f740-d3705e1e88fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab proyects/Tumor_Segmentation_MRI\n"
          ]
        }
      ],
      "source": [
        "# Navigate to My Drive directory to store the dataset\n",
        "%cd /content/drive/MyDrive/colab proyects/Tumor_Segmentation_MRI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Gh9HnkX7GCot",
        "outputId": "7c786ff2-ccf6-4ffc-f560-9ee3a4c75d7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"brain_df\",\n  \"rows\": 3899,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"./data/TCGA_DU_7014_19860618/TCGA_DU_7014_19860618_34.tif\",\n          \"./data/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_24.tif\",\n          \"./data/TCGA_DU_5851_19950428/TCGA_DU_5851_19950428_2.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"./data/TCGA_DU_7014_19860618/TCGA_DU_7014_19860618_34_mask.tif\",\n          \"./data/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_24_mask.tif\",\n          \"./data/TCGA_DU_5851_19950428/TCGA_DU_5851_19950428_2_mask.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "brain_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b4555b1f-26ec-4585-9451-982140ae60e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4555b1f-26ec-4585-9451-982140ae60e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4555b1f-26ec-4585-9451-982140ae60e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4555b1f-26ec-4585-9451-982140ae60e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4cd6bd50-c91f-4348-ab31-2c5ff8e26805\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cd6bd50-c91f-4348-ab31-2c5ff8e26805')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4cd6bd50-c91f-4348-ab31-2c5ff8e26805 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          image_path  \\\n",
              "0  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "1  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "2  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "3  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "4  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "5  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "6  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "7  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "8  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "9  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...   \n",
              "\n",
              "                                           mask_path  mask  \n",
              "0  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
              "1  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
              "2  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
              "3  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
              "4  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
              "5  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
              "6  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  \n",
              "7  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
              "8  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     1  \n",
              "9  ./data/TCGA_CS_4941_19960909/TCGA_CS_4941_1996...     0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "brain_df=pd.read_csv('route_label.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0t5vg-NJzgv"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RFLe9d0J6vp",
        "outputId": "c95c86f1-a0e1-4ab4-effc-30653fe07093"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1366, 3)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the dataframe containing MRIs which have masks associated with them.\n",
        "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
        "brain_df_mask.to_csv(\"segmentation_routes_labels.csv\")\n",
        "brain_df_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "OPSF6Y2NJ8_B"
      },
      "outputs": [],
      "source": [
        "# split the data into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15,random_state=42)\n",
        "X_test, X_val = train_test_split(X_val, test_size=0.5,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "PeqQw7QGQUT6"
      },
      "outputs": [],
      "source": [
        "X_train.to_csv(\"segmentation_train.csv\")\n",
        "X_test.to_csv(\"segmentation_test.csv\")\n",
        "X_val.to_csv(\"segmentation_validation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A40I_6UyocwR"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "learning_rate = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,\n",
        "    validation_split = 0.15,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_generator=datagen.flow_from_dataframe(\n",
        "dataframe=X_train,\n",
        "directory= '.',\n",
        "x_col='image_path',\n",
        "y_col='mask_path',\n",
        "subset=\"training\",\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(256,256)\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator=datagen.flow_from_dataframe(\n",
        "dataframe=X_val,\n",
        "directory= '.',\n",
        "x_col='image_path',\n",
        "y_col='mask_path',\n",
        "subset=\"validation\",\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(256,256))\n",
        "\n",
        "# Create a data generator for test images\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=X_test,\n",
        "directory= '.',\n",
        "x_col='image_path',\n",
        "y_col='mask_path',\n",
        "batch_size=16,\n",
        "shuffle=False,\n",
        "class_mode='categorical',\n",
        "target_size=(256,256))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "NYZ9efuqJ8-H"
      },
      "outputs": [],
      "source": [
        "def resblock(X, f):\n",
        "\n",
        "\n",
        "  # make a copy of input\n",
        "  X_copy = X\n",
        "\n",
        "  # main path\n",
        "  # Read more about he_normal: https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (1,1) ,strides = (1,1),kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "\n",
        "  # Short path\n",
        "  # Read more here: https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\n",
        "\n",
        "  X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n",
        "  X_copy = BatchNormalization()(X_copy)\n",
        "\n",
        "  # Adding the output from main path and short path together\n",
        "\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "k2rIPJmYJ87I"
      },
      "outputs": [],
      "source": [
        "# function to upscale and concatenate the values passsed\n",
        "def upsample_concat(x, skip):\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  merge = Concatenate()([x, skip])\n",
        "\n",
        "  return merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "MzOX-ZOfJ84M"
      },
      "outputs": [],
      "source": [
        "input_shape = (256,256,3)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Stage 1\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "pool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n",
        "\n",
        "# Stage 2\n",
        "conv2_in = resblock(pool_1, 32)\n",
        "pool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n",
        "\n",
        "# Stage 3\n",
        "conv3_in = resblock(pool_2, 64)\n",
        "pool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n",
        "\n",
        "# Stage 4\n",
        "conv4_in = resblock(pool_3, 128)\n",
        "pool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n",
        "\n",
        "# Stage 5 (Bottle Neck)\n",
        "conv5_in = resblock(pool_4, 256)\n",
        "\n",
        "# Upscale stage 1\n",
        "up_1 = upsample_concat(conv5_in, conv4_in)\n",
        "up_1 = resblock(up_1, 128)\n",
        "\n",
        "# Upscale stage 2\n",
        "up_2 = upsample_concat(up_1, conv3_in)\n",
        "up_2 = resblock(up_2, 64)\n",
        "\n",
        "# Upscale stage 3\n",
        "up_3 = upsample_concat(up_2, conv2_in)\n",
        "up_3 = resblock(up_3, 32)\n",
        "\n",
        "# Upscale stage 4\n",
        "up_4 = upsample_concat(up_3, conv1_in)\n",
        "up_4 = resblock(up_4, 16)\n",
        "\n",
        "# Final Output\n",
        "output = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(up_4)\n",
        "\n",
        "model_seg = Model(inputs = X_input, outputs = output )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3toX9GlzKL9y"
      },
      "source": [
        "MINI CHALLENGE #7:\n",
        "- print out the segmentation model summary and list the total number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxY4Crtntitr"
      },
      "outputs": [],
      "source": [
        "model_seg.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5DyqMyWKb_S"
      },
      "source": [
        "# TASK #10: TRAIN A SEGMENTATION RESUNET MODEL TO LOCALIZE TUMOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIHesWPWKil9"
      },
      "source": [
        "## Loss function:\n",
        "\n",
        "We need a custom loss function to train this ResUNet.So,  we have used the loss function as it is from https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py\n",
        "\n",
        "\n",
        "@article{focal-unet,\n",
        "  title={A novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation},\n",
        "  author={Abraham, Nabila and Khan, Naimul Mefraz},\n",
        "  journal={arXiv preprint arXiv:1810.07842},\n",
        "  year={2018}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "4UwSHSDmKjfO"
      },
      "outputs": [],
      "source": [
        "# Utilities file contains the code for custom loss function and custom data generator\n",
        "\n",
        "from utilities import focal_tversky, tversky_loss, tversky"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "N5-Bo7eJKlFd"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "adam = Adam(learning_rate = 0.05, epsilon = 0.1)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "DKYMZkV8KlA0"
      },
      "outputs": [],
      "source": [
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "lr_reduce=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-12),\n",
        "checkpointer = ModelCheckpoint(filepath=\"segmentation_ResUNet.keras\", verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "9AwdLJKUKk_p",
        "outputId": "f5887f94-3835-4b32-a84a-b616f69395c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-211204934.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_reduce\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/colab proyects/Tumor_Segmentation_MRI/utilities.py\u001b[0m in \u001b[0;36mtversky\u001b[0;34m(y_true, y_pred, smooth)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0my_true_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0my_pred_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtrue_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_pos\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0mfalse_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_pos\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mfalse_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_true_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my_pred_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'."
          ]
        }
      ],
      "source": [
        "history = model_seg.fit(training_generator, steps_per_epoch= 70,epochs = 100, validation_data = validation_generator,validation_steps= 30 ,callbacks = [checkpointer, earlystopping,lr_reduce])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G8kJ0Q6Kk-k"
      },
      "outputs": [],
      "source": [
        "# save the model architecture to json file for future use\n",
        "\n",
        "model_json = model_seg.to_json()\n",
        "with open(\"ResUNet-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htn5wbzaLrTS"
      },
      "source": [
        "# TASK #11: ASSESS TRAINED SEGMENTATION RESUNET MODEL PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAvXbuuTKk50"
      },
      "outputs": [],
      "source": [
        "from utilities import focal_tversky, tversky_loss, tversky\n",
        "\n",
        "with open('ResUNet-MRI.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "\n",
        "# load the model architecture\n",
        "model_seg = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_seg.load_weights('weights_seg.hdf5')\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E6GN_4lLykD"
      },
      "outputs": [],
      "source": [
        "# Utilities file contains the code for custom loss function and custom data generator\n",
        "from utilities import prediction\n",
        "\n",
        "# making prediction\n",
        "image_id, mask, has_mask = prediction(test, model, model_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNA7vEDL0Yx"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe for the result\n",
        "df_pred = pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})\n",
        "df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIP8T2JuL2BQ"
      },
      "outputs": [],
      "source": [
        "# Merge the dataframe containing predicted results with the original test data.\n",
        "df_pred = test.merge(df_pred, on = 'image_path')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4yqe9oDL4c4"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(10, 5, figsize=(30, 50))\n",
        "for i in range(len(df_pred)):\n",
        "  if df_pred['has_mask'][i] == 1 and count < 10:\n",
        "    # read the images and convert them to RGB format\n",
        "    img = io.imread(df_pred.image_path[i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axs[count][0].title.set_text(\"Brain MRI\")\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    # Obtain the mask for the image\n",
        "    mask = io.imread(df_pred.mask_path[i])\n",
        "    axs[count][1].title.set_text(\"Original Mask\")\n",
        "    axs[count][1].imshow(mask)\n",
        "\n",
        "    # Obtain the predicted mask for the image\n",
        "    predicted_mask = np.asarray(df_pred.predicted_mask[i])[0].squeeze().round()\n",
        "    axs[count][2].title.set_text(\"AI Predicted Mask\")\n",
        "    axs[count][2].imshow(predicted_mask)\n",
        "\n",
        "    # Apply the mask to the image 'mask==255'\n",
        "    img[mask == 255] = (255, 0, 0)\n",
        "    axs[count][3].title.set_text(\"MRI with Original Mask (Ground Truth)\")\n",
        "    axs[count][3].imshow(img)\n",
        "\n",
        "    img_ = io.imread(df_pred.image_path[i])\n",
        "    img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
        "    img_[predicted_mask == 1] = (0, 255, 0)\n",
        "    axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n",
        "    axs[count][4].imshow(img_)\n",
        "    count += 1\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTrROQGcOheC"
      },
      "source": [
        "MINI CHALLENGE:\n",
        "- Plot 30 images along with their corresponding mask\n",
        "- Visually verify that model predictions made sense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjbpb0q5Nhu_"
      },
      "source": [
        "# EXCELLENT JOB! NOW YOU KNOW HOW TO APPLY AI TO DETECT AND LOCALIZE BRAIN TUMORS. THIS IS A GREAT ACHIEVEMENT IN HEALTHCARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1RThQPC3Z7F"
      },
      "source": [
        "# MINI CHALLENGE SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAeFKeo43jVn"
      },
      "source": [
        "MINI CHALLENGE #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUosqXNi3Xt0"
      },
      "outputs": [],
      "source": [
        "# Obtain the number of images with mask\n",
        "brain_df['mask'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsZzdvDP6k4J"
      },
      "source": [
        "MINI CHALLENGE #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZPaRWMl3x7t"
      },
      "outputs": [],
      "source": [
        "# Advanced Visualization: visualize the MRI scans along with their mask on one image\n",
        "count = 0\n",
        "fig, axs = plt.subplots(12,3, figsize=(20,50))\n",
        "for i in range(len(brain_df)):\n",
        "  if brain_df['mask'][i] == 1 and count < 12:\n",
        "  # read the images\n",
        "    img = io.imread(brain_df.image_path[i])\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axs[count][0].title.set_text(\"Brain MRI\")\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    # obtain the mask for the image\n",
        "    mask = io.imread(brain_df.mask_path[i])\n",
        "    axs[count][1].title.set_text(\"Mask\")\n",
        "    axs[count][1].imshow(mask, cmap = 'gray')\n",
        "\n",
        "    # replace the values in the image with red color (255,0,0) if any mask pixel in the mask was = 255\n",
        "    img[mask == 255] = (255,0,0)\n",
        "    axs[count][2].title.set_text(\"MRI with Mask\")\n",
        "    axs[count][2].imshow(img)\n",
        "    count += 1\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3NmMon_A5s"
      },
      "source": [
        "MINI CHALLENGE #3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlODhS7m_FH3"
      },
      "source": [
        "- An ensemble of these residual nets achieves 3.57% error\n",
        "on the ImageNet test set.\n",
        "- Solution (great article by Siddharth Das): https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRAB2-vZB3Td"
      },
      "source": [
        "MINI CHALLENGE #4:\n",
        "- Negative Transfer occurs when transfer learning negatively affect the model. This occurs when the features of old and new tasks are not related.  \n",
        "- Transfer bounds: Measuring the amount of knowledge transfered is crucial to ensure model quality and robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu5cTrsoDwSk"
      },
      "source": [
        "MINI CHALLENGE #5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBn5fDc_DvzX"
      },
      "outputs": [],
      "source": [
        "# Add classification head to the base model\n",
        "\n",
        "headmodel = basemodel.output\n",
        "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
        "headmodel = Flatten(name= 'flatten')(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(2, activation = 'softmax')(headmodel)\n",
        "\n",
        "model = Model(inputs = basemodel.input, outputs = headmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxiTwwtvB2uN"
      },
      "outputs": [],
      "source": [
        "# Total parameters (original model) = 25,685,634\n",
        "# Total parameters (New model with added dense and dropout layers) = 25,751,426"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNfzveQWIQCH"
      },
      "source": [
        "MINI CHALLENGE #6:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSa29AUc_Ee8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(original,predict, labels = [0,1])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNMrVa00MBgJ"
      },
      "source": [
        "MINI CHALLENGE #7:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5wZshMMPd-"
      },
      "source": [
        "- Total params: 1,210,513"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylcwSXRlQuE6"
      },
      "source": [
        "MINI CHALLENGE #8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxxckSkTMN0D"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(30, 5, figsize=(60, 100))\n",
        "for i in range(len(df_pred)):\n",
        "  if df_pred['has_mask'][i] == 1 and count < 30:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
