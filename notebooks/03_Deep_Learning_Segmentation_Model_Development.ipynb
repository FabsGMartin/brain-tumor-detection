{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0oz3ShXF0Qa"
      },
      "source": [
        "# TASK #2: IMPORT LIBRARIES AND DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDv169iyF3aL",
        "outputId": "ce6fabc5-00d5-431b-9a18-d9af60db91f0"
      },
      "outputs": [],
      "source": [
        "# Configuration and paths\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set base directory\n",
        "BASE_DIR = Path.cwd()\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "MODELS_DIR = BASE_DIR / 'models'\n",
        "\n",
        "# Ensure directories exist\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuration constants\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "IMAGE_SIZE = (256, 256)\n",
        "EPOCHS = 100\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score,RocCurveDisplay, precision_score, f1_score\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oDTMhZP6QNx",
        "outputId": "90256ba7-ed67-4c10-a4f6-89d7d227c33f"
      },
      "outputs": [],
      "source": [
        "# Google Colab code removed - running locally\n",
        "# Data should be in the 'data' directory relative to the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6gXD9ntF7Ob",
        "outputId": "5a43fb47-d560-4937-f912-d711da5eed70"
      },
      "outputs": [],
      "source": [
        "# Google Colab directory change removed - running locally\n",
        "# Working directory is already set to the project root\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh9HnkX7GCot"
      },
      "outputs": [],
      "source": [
        "# Load data from data directory\n",
        "brain_df = pd.read_csv(DATA_DIR / 'route_label.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0t5vg-NJzgv"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RFLe9d0J6vp",
        "outputId": "10161774-2dfd-4f92-b2e3-94aaee68cdba"
      },
      "outputs": [],
      "source": [
        "# Get the dataframe containing MRIs which have masks associated with them.\n",
        "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
        "brain_df_mask.to_csv(DATA_DIR / \"segmentation_routes_labels.csv\")\n",
        "brain_df_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPSF6Y2NJ8_B"
      },
      "outputs": [],
      "source": [
        "# split the data into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "brain_df_mask_train, brain_df_mask_val = train_test_split(brain_df_mask, test_size=0.2,random_state=42)\n",
        "brain_df_mask_test, brain_df_mask_val = train_test_split(brain_df_mask_val, test_size=0.5,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeqQw7QGQUT6"
      },
      "outputs": [],
      "source": [
        "# Save train/test/val splits to data directory\n",
        "brain_df_mask_train.to_csv(DATA_DIR / \"segmentation_train.csv\")\n",
        "brain_df_mask_test.to_csv(DATA_DIR / \"segmentation_test.csv\")\n",
        "brain_df_mask_val.to_csv(DATA_DIR / \"segmentation_validation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A40I_6UyocwR"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw1V1w_HrLsW"
      },
      "outputs": [],
      "source": [
        "# Seed for synchronizing image and mask augmentations\n",
        "SEED = 42\n",
        "\n",
        "# Generator WITH augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Generator WITHOUT augmentation for validation/test\n",
        "val_datagen = ImageDataGenerator(rescale=1./255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h17rX4MjrLsW"
      },
      "outputs": [],
      "source": [
        "def train_generator_fn():\n",
        "    \"\"\"Training generator with synchronized augmentation for image and mask.\"\"\"\n",
        "    image_generator = train_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_train,\n",
        "        x_col='image_path',\n",
        "        class_mode=None,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,  # Same seed for synchronization\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    mask_generator = train_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_train,\n",
        "        x_col=\"mask_path\",\n",
        "        class_mode=None,\n",
        "        color_mode=\"grayscale\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,  # Same seed - ensures identical transformations\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        img = next(image_generator)\n",
        "        msk = next(mask_generator)\n",
        "        # Binarize masks (augmentation can create intermediate values)\n",
        "        msk = (msk > 0.5).astype(np.float32)\n",
        "        yield (img, msk)\n",
        "\n",
        "training_generator = train_generator_fn()\n",
        "\n",
        "\n",
        "def val_generator_fn():\n",
        "    \"\"\"Validation generator WITHOUT augmentation.\"\"\"\n",
        "    image_generator_val = val_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_val,\n",
        "        x_col='image_path',\n",
        "        class_mode=None,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=False  # No shuffle for validation\n",
        "    )\n",
        "\n",
        "    mask_generator_val = val_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_val,\n",
        "        x_col=\"mask_path\",\n",
        "        class_mode=None,\n",
        "        color_mode=\"grayscale\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        img = next(image_generator_val)\n",
        "        msk = next(mask_generator_val)\n",
        "        # Binarize masks\n",
        "        msk = (msk > 0.5).astype(np.float32)\n",
        "        yield (img, msk)\n",
        "\n",
        "validation_generator = val_generator_fn()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYZ9efuqJ8-H"
      },
      "outputs": [],
      "source": [
        "def resblock(X, f):\n",
        "\n",
        "\n",
        "  # make a copy of input\n",
        "  X_copy = X\n",
        "\n",
        "  # main path\n",
        "  # Read more about he_normal: https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (1,1) ,strides = (1,1),kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "\n",
        "  # Short path\n",
        "  # Read more here: https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\n",
        "\n",
        "  X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n",
        "  X_copy = BatchNormalization()(X_copy)\n",
        "\n",
        "  # Adding the output from main path and short path together\n",
        "\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2rIPJmYJ87I"
      },
      "outputs": [],
      "source": [
        "# function to upscale and concatenate the values passsed\n",
        "def upsample_concat(x, skip):\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  merge = Concatenate()([x, skip])\n",
        "\n",
        "  return merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzOX-ZOfJ84M"
      },
      "outputs": [],
      "source": [
        "input_shape = (256,256,3)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Stage 1\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "pool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n",
        "\n",
        "# Stage 2\n",
        "conv2_in = resblock(pool_1, 32)\n",
        "pool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n",
        "\n",
        "# Stage 3\n",
        "conv3_in = resblock(pool_2, 64)\n",
        "pool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n",
        "\n",
        "# Stage 4\n",
        "conv4_in = resblock(pool_3, 128)\n",
        "pool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n",
        "\n",
        "# Stage 5 (Bottle Neck)\n",
        "conv5_in = resblock(pool_4, 256)\n",
        "\n",
        "# Upscale stage 1\n",
        "up_1 = upsample_concat(conv5_in, conv4_in)\n",
        "up_1 = resblock(up_1, 128)\n",
        "\n",
        "# Upscale stage 2\n",
        "up_2 = upsample_concat(up_1, conv3_in)\n",
        "up_2 = resblock(up_2, 64)\n",
        "\n",
        "# Upscale stage 3\n",
        "up_3 = upsample_concat(up_2, conv2_in)\n",
        "up_3 = resblock(up_3, 32)\n",
        "\n",
        "# Upscale stage 4\n",
        "up_4 = upsample_concat(up_3, conv1_in)\n",
        "up_4 = resblock(up_4, 16)\n",
        "\n",
        "# Final Output\n",
        "output = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(up_4)\n",
        "\n",
        "model_seg = Model(inputs = X_input, outputs = output )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZxY4Crtntitr",
        "outputId": "a70b1ee0-5b7d-401b-f815-0e4ea9806b68"
      },
      "outputs": [],
      "source": [
        "model_seg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yZBYATH656T",
        "outputId": "0dd24260-c7dd-424c-a2b6-84a5bda0a348"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (\n",
        "        tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth\n",
        "    )\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "    dl = dice_loss(y_true, y_pred)\n",
        "    return bce + dl\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    total = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "    union = total - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "model_seg.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "              loss=bce_dice_loss,\n",
        "              metrics=[dice_coef, iou_coef, 'accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(str(MODELS_DIR / \"segmentation_ResUNet6.keras\"), save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\n",
        "]\n",
        "\n",
        "steps_per_epoch_calc = len(brain_df_mask_train) // BATCH_SIZE\n",
        "validation_steps_calc = len(brain_df_mask_val) // BATCH_SIZE\n",
        "\n",
        "history = model_seg.fit(\n",
        "    training_generator, # Use the direct Python generator\n",
        "    steps_per_epoch=steps_per_epoch_calc,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator, # Use the direct Python generator\n",
        "    validation_steps=validation_steps_calc,\n",
        "    callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loCPCyvUY7ZY"
      },
      "outputs": [],
      "source": [
        "# Evaluation Visualization\n",
        "plt.figure(figsize=(8, 20))\n",
        "\n",
        "# --- Loss ---\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], 'r-', label='Validation Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# --- IoU ---\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(history.history['iou_coef'], 'b-', label='Train IoU')\n",
        "plt.plot(history.history['val_iou_coef'], 'r-', label='Validation IoU')\n",
        "plt.legend(loc='best')\n",
        "plt.title('IoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "\n",
        "# --- Dice Coefficient ---\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(history.history['dice_coef'], 'b-', label='Train Dice')\n",
        "plt.plot(history.history['val_dice_coef'], 'r-', label='Validation Dice')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Dice Coefficient')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice')\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(history.history['accuracy'], 'b-', label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnK5F3yIaXh3"
      },
      "outputs": [],
      "source": [
        "loaded_model_seg=load_model(str(MODELS_DIR / \"segmentation_ResUNet6.keras\"), custom_objects={\"bce_dice_loss\":bce_dice_loss, \"dice_coef\":dice_coef, \"iou_coef\":iou_coef})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E6GN_4lLykD"
      },
      "outputs": [],
      "source": [
        "def test_generator_fn():\n",
        "    \"\"\"Test generator WITHOUT augmentation - uses val_datagen.\"\"\"\n",
        "    image_generator_test = val_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_test,\n",
        "        x_col='image_path',\n",
        "        class_mode=None,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=False  # No shuffle for test\n",
        "    )\n",
        "\n",
        "    mask_generator_test = val_datagen.flow_from_dataframe(\n",
        "        brain_df_mask_test,\n",
        "        x_col=\"mask_path\",\n",
        "        class_mode=None,\n",
        "        color_mode=\"grayscale\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        img = next(image_generator_test)\n",
        "        msk = next(mask_generator_test)\n",
        "        # Binarize masks\n",
        "        msk = (msk > 0.5).astype(np.float32)\n",
        "        yield (img, msk)\n",
        "\n",
        "test_generator = test_generator_fn()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VnLjxyNz0YC"
      },
      "outputs": [],
      "source": [
        "\n",
        "loaded_model_seg=load_model(str(MODELS_DIR / \"segmentation_ResUNet6.keras\"), custom_objects={\"bce_dice_loss\":bce_dice_loss, \"dice_coef\":dice_coef, \"iou_coef\":iou_coef})\n",
        "prediction_seg = loaded_model_seg.evaluate(test_generator, steps=len(brain_df_mask_test) // BATCH_SIZE, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOectlhAz8cQ"
      },
      "outputs": [],
      "source": [
        "print(f\" Test Accuracy: {prediction_seg[3]:.4f}\")\n",
        "print(f\" Test Dice Coefficient: {prediction_seg[1]:.4f}\")\n",
        "print(f\" Test IoU: {prediction_seg[2]:.4f}\")\n",
        "print(f\" Test Loss: {prediction_seg[0]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRd8spYId5He"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "'''\n",
        "    # Ensure enough samples exist in both categories\n",
        "    tumor_indices = random.sample(tumor_indices, min(num_per_class, len(tumor_indices)))\n",
        "    non_tumor_indices = random.sample(non_tumor_indices, min(num_per_class, len(non_tumor_indices)))\n",
        "\n",
        "    selected_indices = tumor_indices + non_tumor_indices\n",
        "    total_samples = len(selected_indices)\n",
        "\n",
        "    plt.figure(figsize=(12, total_samples * 2.5))\n",
        "\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        image = X_test[idx]\n",
        "        true_mask = y_test[idx]\n",
        "\n",
        "        # Predict mask\n",
        "        pred_mask = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "        pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        # Titles\n",
        "        label = \"Tumor\" if np.any(true_mask > 0) else \"Non-Tumor\"\n",
        "\n",
        "        # Original MRI\n",
        "        plt.subplot(total_samples, 3, i*3 + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"{label} - MRI\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Ground truth mask\n",
        "        plt.subplot(total_samples, 3, i*3 + 2)\n",
        "        plt.imshow(true_mask.squeeze(), cmap='gray')\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Predicted mask\n",
        "        plt.subplot(total_samples, 3, i*3 + 3)\n",
        "        plt.imshow(pred_mask.squeeze(), cmap='gray')\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run visualization\n",
        "visualize_predictions(model, X_test, y_test, num_per_class=4)\n",
        "'''\n",
        "selected_routes=brain_df_mask_test.sample(5)\n",
        "\n",
        "plt.figure(figsize=(15,25))\n",
        "for i in range(len(selected_routes)):\n",
        "\n",
        "  plt.subplot(5,3,1+3*(i))\n",
        "  image = cv2.cvtColor(io.imread(selected_routes.image_path.iloc[i]), cv2.COLOR_BGR2RGB)/255\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(5,3,2+3*(i))\n",
        "  true_mask = cv2.cvtColor(io.imread(selected_routes.mask_path.iloc[i]), cv2.COLOR_BGR2RGB)/255\n",
        "  plt.imshow(true_mask)\n",
        "  plt.axis('off')\n",
        "\n",
        "\n",
        "  plt.subplot(5,3,3+3*(i))\n",
        "  pred_mask=model_seg.predict(np.expand_dims(image, axis=0))[0]\n",
        "  pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "  plt.imshow(pred_mask, cmap='gray')\n",
        "  plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions for all test images\n",
        "image_id = []\n",
        "mask = []\n",
        "has_mask = []\n",
        "\n",
        "print(\"Generating predictions for test set...\")\n",
        "for i in range(len(brain_df_mask_test)):\n",
        "    # Get image path\n",
        "    img_path = brain_df_mask_test.image_path.iloc[i]\n",
        "\n",
        "    # Read and preprocess image\n",
        "    image = cv2.cvtColor(io.imread(img_path), cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "    # Predict mask\n",
        "    pred_mask = loaded_model_seg.predict(np.expand_dims(image, axis=0), verbose=0)[0]\n",
        "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Store results\n",
        "    image_id.append(img_path)\n",
        "    mask.append(pred_mask)\n",
        "    has_mask.append(1)  # All images in brain_df_mask_test have masks\n",
        "\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(brain_df_mask_test)} images\")\n",
        "\n",
        "print(f\"Completed! Generated predictions for {len(image_id)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNA7vEDL0Yx"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe for the result\n",
        "df_pred = pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})\n",
        "df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIP8T2JuL2BQ"
      },
      "outputs": [],
      "source": [
        "# Merge the dataframe containing predicted results with the original test data.\n",
        "df_pred = brain_df_mask_test.merge(df_pred, on='image_path')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4yqe9oDL4c4"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(10, 5, figsize=(30, 50))\n",
        "for i in range(len(df_pred)):\n",
        "  if df_pred['has_mask'][i] == 1 and count < 10:\n",
        "    # read the images and convert them to RGB format\n",
        "    img = io.imread(df_pred.image_path[i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axs[count][0].title.set_text(\"Brain MRI\")\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    # Obtain the mask for the image\n",
        "    mask = io.imread(df_pred.mask_path[i])\n",
        "    axs[count][1].title.set_text(\"Original Mask\")\n",
        "    axs[count][1].imshow(mask)\n",
        "\n",
        "    # Obtain the predicted mask for the image\n",
        "    predicted_mask = np.array(df_pred.predicted_mask[i])\n",
        "    # Ensure it's 2D (256, 256)\n",
        "    if predicted_mask.ndim > 2:\n",
        "        predicted_mask = predicted_mask.squeeze()\n",
        "    if predicted_mask.ndim == 1:\n",
        "        # If somehow flattened, reshape it\n",
        "        predicted_mask = predicted_mask.reshape(256, 256)\n",
        "    predicted_mask = predicted_mask.round().astype(np.uint8)\n",
        "    axs[count][2].title.set_text(\"AI Predicted Mask\")\n",
        "    axs[count][2].imshow(predicted_mask, cmap='gray')\n",
        "\n",
        "    # Apply the mask to the image 'mask==255'\n",
        "    img[mask == 255] = (255, 0, 0)\n",
        "    axs[count][3].title.set_text(\"MRI with Original Mask (Ground Truth)\")\n",
        "    axs[count][3].imshow(img)\n",
        "\n",
        "    img_ = io.imread(df_pred.image_path[i])\n",
        "    img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
        "    img_[predicted_mask == 1] = (0, 255, 0)\n",
        "    axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n",
        "    axs[count][4].imshow(img_)\n",
        "    count += 1\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTrROQGcOheC"
      },
      "source": [
        "MINI CHALLENGE:\n",
        "- Plot 30 images along with their corresponding mask\n",
        "- Visually verify that model predictions made sense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjbpb0q5Nhu_"
      },
      "source": [
        "# EXCELLENT JOB! NOW YOU KNOW HOW TO APPLY AI TO DETECT AND LOCALIZE BRAIN TUMORS. THIS IS A GREAT ACHIEVEMENT IN HEALTHCARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1RThQPC3Z7F"
      },
      "source": [
        "# MINI CHALLENGE SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAeFKeo43jVn"
      },
      "source": [
        "MINI CHALLENGE #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUosqXNi3Xt0"
      },
      "outputs": [],
      "source": [
        "# Obtain the number of images with mask\n",
        "brain_df['mask'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsZzdvDP6k4J"
      },
      "source": [
        "MINI CHALLENGE #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZPaRWMl3x7t"
      },
      "outputs": [],
      "source": [
        "# Advanced Visualization: visualize the MRI scans along with their mask on one image\n",
        "count = 0\n",
        "fig, axs = plt.subplots(12,3, figsize=(20,50))\n",
        "for i in range(len(brain_df)):\n",
        "  if brain_df['mask'][i] == 1 and count < 12:\n",
        "  # read the images\n",
        "    img = io.imread(brain_df.image_path[i])\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axs[count][0].title.set_text(\"Brain MRI\")\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    # obtain the mask for the image\n",
        "    mask = io.imread(brain_df.mask_path[i])\n",
        "    axs[count][1].title.set_text(\"Mask\")\n",
        "    axs[count][1].imshow(mask, cmap = 'gray')\n",
        "\n",
        "    # replace the values in the image with red color (255,0,0) if any mask pixel in the mask was = 255\n",
        "    img[mask == 255] = (255,0,0)\n",
        "    axs[count][2].title.set_text(\"MRI with Mask\")\n",
        "    axs[count][2].imshow(img)\n",
        "    count += 1\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3NmMon_A5s"
      },
      "source": [
        "MINI CHALLENGE #3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlODhS7m_FH3"
      },
      "source": [
        "- An ensemble of these residual nets achieves 3.57% error\n",
        "on the ImageNet test set.\n",
        "- Solution (great article by Siddharth Das): https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRAB2-vZB3Td"
      },
      "source": [
        "MINI CHALLENGE #4:\n",
        "- Negative Transfer occurs when transfer learning negatively affect the model. This occurs when the features of old and new tasks are not related.  \n",
        "- Transfer bounds: Measuring the amount of knowledge transfered is crucial to ensure model quality and robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu5cTrsoDwSk"
      },
      "source": [
        "MINI CHALLENGE #5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBn5fDc_DvzX"
      },
      "outputs": [],
      "source": [
        "# Add classification head to the base model\n",
        "\n",
        "headmodel = basemodel.output\n",
        "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
        "headmodel = Flatten(name= 'flatten')(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(2, activation = 'softmax')(headmodel)\n",
        "\n",
        "model = Model(inputs = basemodel.input, outputs = headmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxiTwwtvB2uN"
      },
      "outputs": [],
      "source": [
        "# Total parameters (original model) = 25,685,634\n",
        "# Total parameters (New model with added dense and dropout layers) = 25,751,426"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNfzveQWIQCH"
      },
      "source": [
        "MINI CHALLENGE #6:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSa29AUc_Ee8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(original,predict, labels = [0,1])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNMrVa00MBgJ"
      },
      "source": [
        "MINI CHALLENGE #7:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5wZshMMPd-"
      },
      "source": [
        "- Total params: 1,210,513"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylcwSXRlQuE6"
      },
      "source": [
        "MINI CHALLENGE #8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxxckSkTMN0D"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(30, 5, figsize=(60, 100))\n",
        "for i in range(len(df_pred)):\n",
        "  if df_pred['has_mask'][i] == 1 and count < 30:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TASK #7: ASSESS TRAINED MODEL PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained model (instead of training the model for 1+ hours)\n",
        "\n",
        "model=load_model('./classifier-resnet-model6.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make prediction\n",
        "\n",
        "test_predict = model.predict(test_generator, steps = test_generator.n // 16, verbose =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the predicted class from the model prediction\n",
        "predict = []\n",
        "\n",
        "for i in test_predict:\n",
        "  predict.append(str(np.argmax(i)))\n",
        "\n",
        "predict = np.asarray(predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since we have used test generator, it limited the images to len(predict), due to batch size\n",
        "original = np.asarray(test['mask'])[:len(predict)]\n",
        "len(original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(original, predict)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(original, predict)\n",
        "plt.figure(figsize = (7,7))\n",
        "sns.heatmap(cm, annot=True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MINI CHALLENGE #6:\n",
        "- Print out the classification report and comment on the precision, recall and F1-score results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(original, predict, labels = [0,1])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINED MODEL TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained modeL\n",
        "\n",
        "model=load_model('./classifier-resnet-model9.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_predict = model.predict(test_generator, steps = test_generator.n // 16, verbose =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the predicted class from the model prediction\n",
        "predict = []\n",
        "\n",
        "for i in test_predict:\n",
        "  predict.append(str(np.argmax(i)))\n",
        "\n",
        "predict = np.asarray(predict)\n",
        "predict = predict.astype(\"object\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# since we have used test generator, it limited the images to len(predict), due to batch size\n",
        "original = np.asarray(test['mask'])[:len(predict)]\n",
        "len(original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the accuracy of the model\n",
        "\n",
        "print(\"accuracy_score: \", accuracy_score(original, predict))\n",
        "print(\"f1_score: \", f1_score(original, predict,pos_label=\"1\"))\n",
        "print(\"precision_score: \", precision_score(original, predict,pos_label=\"1\"))\n",
        "print(\"recall_score: \", recall_score(original, predict,pos_label=\"1\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(original, predict, labels = [0,1])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(original, predict)\n",
        "plt.figure(figsize = (7,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original=original.astype(\"int\")\n",
        "predict=predict.astype(\"int\")\n",
        "RocCurveDisplay.from_predictions(original, predict);\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
